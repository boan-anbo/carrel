{"_scroll_id":"FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFm1kMUlJUjhQUlpXb0NaeDRCVEh3cmcAAAAAAABEEBZwVWF1eEltaVRqLWZIWERWaTZVUk1B","_shards":{"failed":0,"skipped":0,"successful":1,"total":1},"hits":{"hits":[{"_id":"-JFSu4IBzLTTH-8HZiji","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":0,"pages":518,"text":"ARTIFICIAL \r\nINTELLIGENCE\r\nA Systems Approach\r\n","uuid":"abe7e05b-72c2-4b0f-b8f5-0a2a8bfded8a"},"_type":"pdf"},{"_id":"-ZFSu4IBzLTTH-8HZijl","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":1,"pages":518,"text":"LICENSE, DISCLAIMER OF LIABILITY, AND LIMITED WARRANTY\r\nThe CD-ROM that accompanies this book may only be used on a single PC. This license does \r\nnot permit its use on the Internet or on a network (of any kind). By purchasing or using this \r\nbook/CD-ROM package(the “Work”), you agree that this license grants permission to use the \r\nproducts contained herein, but does not give you the right of ownership to any of the textual \r\ncontent in the book or ownership to any of the information or products contained on the \r\nCD-ROM. Use of third party software contained herein is limited to and subject to licensing \r\nterms for the respective products, and permission must be obtained from the publisher or the \r\nowner of the software in order to reproduce or network any portion of the textual material \r\nor software (in any media) that is contained in the Work.\r\nINFINITY SCIENCE PRESS LLC (“ISP” or “the Publisher”) and anyone involved in the \r\ncreation, writing or production of the accompanying algorithms, code, or computer programs \r\n(“the software”) or any of the third party software contained on the CD-ROM or any of the \r\ntextual material in the book, cannot and do not warrant the performance or results that might \r\nbe obtained by using the software or contents of the book. The authors, developers, and the \r\npublisher have used their best efforts to insure the accuracy and functionality of the textual \r\nmaterial and programs contained in this package; we, however, make no warranty of any kind, \r\nexpress or implied, regarding the performance of these contents or programs. The Work is \r\nsold “as is” without warranty (except for defective materials used in manufacturing the disc \r\nor due to faulty workmanship);\r\nThe authors, developers, and the publisher of any third party software, and anyone involved \r\nin the composition, production, and manufacturing of this work will not be liable for damages \r\nof any kind arising out of the use of (or the inability to use) the algorithms, source code, \r\ncomputer programs, or textual material contained in this publication. This includes, but is not \r\nlimited to, loss of revenue or profit, or other incidental, physical, or consequential damages \r\narising out of the use of this Work.\r\nThe sole remedy in the event of a claim of any kind is expressly limited to replacement of \r\nthe book and/or the CD-ROM, and only at the discretion of the Publisher.\r\nThe use of “implied warranty” and certain “exclusions” vary from state to state, and might \r\nnot apply to the purchaser of this product.\r\n","uuid":"19c1b2cf-a725-4f86-ba29-411189ed9da8"},"_type":"pdf"},{"_id":"-pFSu4IBzLTTH-8HZijo","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":2,"pages":518,"text":"ARTIFICIAL \r\nINTELLIGENCE\r\n \r\nA Systems Approach\r\nM. TIM JONES\r\nINFINITY SCIENCE PRESS LLC\r\nHingham, Massachusetts\r\nNew Delhi\r\n","uuid":"b7803404-488e-4306-96f0-8e97ad2da2d1"},"_type":"pdf"},{"_id":"-5FSu4IBzLTTH-8HZijr","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":3,"pages":518,"text":"Copyright 2008 by INFINITY SCIENCE PRESS LLC\r\nAll rights reserved.\r\nThis publication, portions of it, or any accompanying software may not be reproduced in any way, stored in a retrieval \r\nsystem of any type, or transmitted by any means or media, electronic or mechanical, including, but not limited to, \r\nphotocopy, recording, Internet postings or scanning, without prior permission in writing from the publisher.\r\nPublisher: DAVID PALLAI\r\nINFINITY SCIENCE PRESS LLC\r\n11 Leavitt Street\r\nHingham, MA 02043\r\nTel. 877-266-5796 (toll free)\r\nFax 781-740-1677\r\ninfo@infinitysciencepress.com\r\nwww.infinitysciencepress.com\r\nThis book is printed on acid-free paper.\r\nM. Tim Jones. Artificial Intelligence: A Systems Approach \r\nISBN: 978-0-9778582-3-1\r\nThe publisher recognizes and respects all marks used by companies, manufacturers, and developers \r\nas a means to distinguish their products. All brand names and product names mentioned in this \r\nbook are trademarks or service marks of their respective companies. Any omission or misuse (of any \r\nkind) of service marks or trademarks, etc. is not an attempt to infringe on the property of others. \r\nLibrary of Congress Cataloging-in-Publication Data\r\nJONES, M. TIM.\r\n Artificial intelligence : a systems approach / M. Tim Jones.\r\n  p. cm.\r\n Includes index.\r\n ISBN-13: 978-0-9778582-3-1 (hardcover with cd-rom : alk. paper)\r\n 1. Artificial intelligence--Data processing. 2. Artificial intelligence--Mathematical models. I. Title.\r\n Q336.J68 2008\r\n 006.3--dc22\r\n2007045869\r\n7 8 9 0 4 3 2 1\r\nOur titles are available for adoption, license or bulk purchase by institutions, corporations, etc. For \r\nadditional information, please contact the Customer Service Dept. at 877-266-5796 (toll free).\r\nRequests for replacement of a defective CD-ROM must be accompanied by the original disc, your \r\nmailing address, telephone number, date of purchase and purchase price. Please state the nature of the \r\nproblem, and send the information to INFINITY SCIENCE PRESS, 11 Leavitt Street, Hingham, MA 02043.\r\nThe sole obligation of INFINITY SCIENCE PRESS to the purchaser is to replace the disc, based on defective \r\nmaterials or faulty workmanship, but not based on the operation or functionality of the product.\r\n","uuid":"2768cddf-2fba-4ba4-9d14-936dfd9b6b53"},"_type":"pdf"},{"_id":"_JFSu4IBzLTTH-8HZijt","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":4,"pages":518,"text":"DEDICATION\r\nThis book is dedicated to my wonderful wife, Jill, without whom this book would not be \r\npossible. I’m also indebted to my parents Maury and Celeta, who instilled in me a desire to \r\nlearn and wonder.\r\n","uuid":"951a21b2-5c62-45b1-b5a1-4d7c09257f22"},"_type":"pdf"},{"_id":"_ZFSu4IBzLTTH-8HZijw","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":5,"pages":518,"text":"ACKNOWLEDGMENTS\r\nAt the time of this writing, AI is celebrating its 50th anniversary. It was August of 1956 when \r\nresearchers met at the Dartmouth Summer Research Project on Artificial Intelligence with \r\nthe agenda of creating intelligent machines. In the 50 years that followed, AI has become a \r\ngenuine field of study, but the road has not been without its bumps.\r\nAcknowledging all those who’ve contributed to AI would fill a book much larger than \r\nthis. But I’d like to personally recognize John McCarthy for introducing AI in 1955 (at the \r\nDartmouth Summer Project) and for having created the wonderful Lisp programming \r\nlanguage.\r\n","uuid":"874c8365-2385-4fec-892c-ebd9ae297716"},"_type":"pdf"},{"_id":"_pFSu4IBzLTTH-8HZijy","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":6,"pages":518,"text":"TABLE OF CONTENTS\r\nChapter 1 The History of AI 1-19\r\n What is Intelligence? 1\r\n The Search for Mechanical Intelligence 2\r\n The Very Early Days (the early 1950’s) 3\r\n  Alan Turing 3\r\n  AI, Problem Solving and Games 4\r\n Artificial Intelligence Emerges as a Field 5\r\n  The Dartmouth AI Summer Research Project 5\r\n  Building Tools for AI 6\r\n  The Focus on Strong AI 6\r\n  Constrained Applications 7\r\n  Bottom-Up Approaches Emerge 7\r\n AI’s Winter 8\r\n  Results-Oriented Applications 8\r\n  Additional AI Tools Emerge 9\r\n  Neat vs. Scruffy Approaches 9\r\n AI Remerges 10\r\n  The Silent Return 10\r\n  Messy and Scruffy Approaches Take Hold 10\r\n  Agent Systems 12\r\n AI Inter-disciplinary R&D 12\r\n Systems Approach 13\r\n Overview of this Book 15\r\n  Uninformed Search 15\r\n  Informed Search 15\r\n  AI and Games 15\r\n  Knowledge Representation 16\r\n","uuid":"6cdbe991-6922-4a61-9b33-2e39f6021331"},"_type":"pdf"},{"_id":"_5FSu4IBzLTTH-8HZij1","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":7,"pages":518,"text":"  Machine Learning 16\r\n  Evolutionary Computation 16\r\n  Neural Networks Part 1 16\r\n  Neural Networks Part 2 17\r\n  Intelligent Agents 17\r\n  Biologically Inspired and Hybrid Models 17\r\n  Languages of AI 17\r\n Chapter Summary 18\r\n References 18\r\n Resources 18\r\n Exercises 19\r\nChapter 2 Uninformed Search 21-48\r\nSearch and AI 21\r\nClasses of Search 22\r\nGeneral State Space Search 22\r\n  Search in a Physical Space 22\r\n  Search in a Puzzle Space 23\r\n  Search in an Adversarial Game Space 25\r\nTrees, Graphs and Representation 27\r\nUninformed Search 29\r\n  Helper APIs 30\r\n  General Search Paradigms 31\r\n  Depth-First Search 31\r\n  Depth-Limited Search 34\r\n  Iterative Deepening Search 36\r\n  Breadth-First Search 39\r\n  Bidirectional Search 42\r\n  Uniform-Cost Search 42\r\nImprovements 45\r\nAlgorithm Advantages 46\r\nChapter Summary 46\r\nAlgorithms Summary 46\r\nReferences  47\r\nExercises  47\r\nChapter 3 Informed Search 49-88\r\nSearch and AI 49\r\nBest-First Search 50\r\n Best-First Search and the N-Queens Problem 50\r\n","uuid":"c5917c3c-5e4b-442a-bb84-72b705195653"},"_type":"pdf"},{"_id":"AJFSu4IBzLTTH-8HZin3","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":8,"pages":518,"text":" Best-First Search Implementation 52\r\n Variants of Best-First Search 56\r\nA* Search  57\r\n A* Search and the Eight Puzzle 59\r\n Eight Puzzle Representation 59\r\n A* Search Implementation 61\r\n Eight Puzzle Demonstration with A* 64\r\n A* Variants 65\r\n Applications of A* Search 65\r\nHill Climbing Search 65\r\nSimulated Annealing 66\r\n The Traveling Salesman Problem (TSP) 68\r\n TSP Tour Representation 68\r\n Simulated Annealing Implementation 70\r\n Simulated Annealing Demonstration 73\r\nTabu Search 75\r\n Tabu Search Implementation 77\r\n Tabu Search Demonstration 79\r\n Tabu Search Variants 80\r\nConstraint Satisfaction 81\r\n Graph Coloring as a CSP 81\r\n Scheduling as CSP 83\r\nConstraint Satisfaction Problems 84\r\n Generate and Test 84\r\n Backtracking 84\r\n Forward Checking and Look Ahead 84\r\n Min-Conflicts Search 86\r\nChapter Summary 86\r\nAlgorithms Summary 86\r\nReferences  86\r\nResources  87\r\nExercises  87\r\nChapter 4 AI and Games 89-142\r\nTwo Player Games 89\r\nThe Minimax Algorithm 92\r\n Minimax and Tic-Tac-Toe 95\r\n Minimax Implementation for Tic-Tac-Toe 98\r\n Minimax with Alpha-Beta Pruning 101\r\nClassical Game AI 106\r\n","uuid":"3669ad9b-a765-44d5-8537-fe5ed93951d3"},"_type":"pdf"},{"_id":"AZFSu4IBzLTTH-8HZin6","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":9,"pages":518,"text":" Checkers 106\r\n  Checker Board Representation 107\r\n  Techniques used in Checkers Programs 107\r\n   Opening Books 108\r\n   Static Evaluation Function 108\r\n   Search Algorithm 108\r\n   Move History 108\r\n   Endgame Database 109\r\n Chess  109\r\n  Chess Board Representation 110\r\n  Techniques used in Chess Programs 110\r\n   Opening Book Database 110\r\n   Minimax Search with Alpha Beta Pruning 111\r\n   Static Board Evaluation 111\r\n Othello  112\r\n  Techniques used in Othello Programs 112\r\n   Opening Knowledge 112\r\n   Static Evaluation Function 112\r\n   Search Algorithm 113\r\n   Endgames 113\r\n   Other Algorithms 113\r\n Go   114\r\n  Go Board Representation 114\r\n  Techniques used in Go Programs 114\r\n   Opening Moves 115\r\n   Move Generation 115\r\n   Evaluation 115\r\n   Endgame 116\r\n Backgammon 116\r\n  Techniques used in Backgammon Programs 116\r\n   Neurogammon 116\r\n   TD-Gammon 117\r\n Poker  118\r\n  Loki – A learning Poker Player 119\r\n Scrabble 120\r\nVideo Game AI 121\r\n Applications of AI Algorithms in Video Games 122\r\n  Movement and Pathfinding 123\r\n   Table Lookup with Offensive and Defensive Strategy 123\r\n  NPC Behavior 129\r\n","uuid":"05e459c5-bbce-4c6a-8fa1-7a149e2f3fa4"},"_type":"pdf"},{"_id":"ApFSu4IBzLTTH-8HZin8","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":10,"pages":518,"text":"   Static State Machines 130\r\n   Layered Behavior Architectures 131\r\n   Other Action-Selection Mechanisms 132\r\n  Team AI 132\r\n   Goals and Plans 134\r\n  Real-Time Strategy AI 136\r\n   Rules-Based Programming 136\r\nChapter Summary 139\r\nReferences  139\r\nResources  140\r\nExercises  141\r\nChapter 5 Knowledge Representation 143-170\r\n Introduction 143\r\n Types of Knowledge 144\r\n The Role of Knowledge 144\r\n Semantic Nets 145\r\n Frames  146\r\n Proposi tional Logic 149\r\n  Deductive Reasoning with Propositional Logic 151\r\n  Limitations of Propositional Logic 152\r\n First Order Logic (Predicate Logic) 152\r\n  Atomic Sentences 153\r\n  Compound Sentences 154\r\n  Variables 154\r\n  Quantifiers 155\r\n  First-Order Logic and Prolog 155\r\n   Simple Example 155\r\n   Information Retrieval and KR 157\r\n   Representing and Reasoning about an Environment 159\r\n Semantic Web 163\r\n Computational Knowledge Discovery 165\r\n  The BACON System 165\r\n  Automatic Mathematician 166\r\n Ontology 167\r\n Communication of Knowledge 167\r\n Common Sense 168\r\n Summary 169\r\n References 169\r\n Resources 169\r\n","uuid":"7cff4e4a-2413-4022-8f6b-0616d3319e94"},"_type":"pdf"},{"_id":"A5FSu4IBzLTTH-8HZin_","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":11,"pages":518,"text":" Exercises 170\r\nChapter 6 Machine Learning 171-193\r\n Machine Learning Algorithms 171\r\n  Supervised Learning 172\r\n   Learning with Decision Trees 172\r\n    Creating a Decision Tree 174\r\n   Characteristics of Decision Tree Learning 176\r\n  Unsupervised Learning 176\r\n   Markov Models 177\r\n    Word Learning with Markov Chains 177\r\n    Word Generation with Markov Chains 179\r\n    Markov Chain Implementation 180\r\n    Other Applications of Markov Chains 184\r\n   Nearest Neighbor Classification 185\r\n    1NN Example 186\r\n    k-NN Example 188\r\n Summary 192\r\n Resources 192\r\n Exercises 192\r\nChapter 7 Evolutionary Computation 195-247\r\n Short History of Evolutionary Computation 195\r\n  Evolutionary Strategies 196\r\n  Evolutionary Programming 197\r\n  Genetic Algorithms 197\r\n  Genetic Programming 198\r\n Biological Motivation 199\r\n Genetic Algorithms 200\r\n  Genetic Algorithm Overview 200\r\n  Genetic Algorithm Implementation 204\r\n Genetic Programming 212\r\n  Genetic Programming Algorithm 212\r\n  Genetic Programming Implementation 215\r\n Evolutionary Strategies 220\r\n  Evolutionary Strategies Algorithm 221\r\n  Evolutionary Strategies Implementation 223\r\n Differential Evolution 227\r\n  Differential Evolution Algorithm 228\r\n  Differential Evolution Implementation 230\r\n","uuid":"a70e8b92-a0cd-4371-be45-d3bdc723229d"},"_type":"pdf"},{"_id":"BJFSu4IBzLTTH-8HZykC","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":12,"pages":518,"text":" Particle Swarm Optimization 236\r\n  Particle Swarm Algorithm 236\r\n  Particle Swarm Implementation 238\r\n Evolvable Hardware 244\r\n Summary 244\r\n References 245\r\n Resources 245\r\n Exercises 245\r\nChapter 8 Neural Networks I 249-287\r\nShort History of Neural Networks 249\r\nBiological Motiviation 250\r\nFundamentals of Neural Networks 251\r\n Single Layer Perceptrons 252\r\n Multi-Layer Perceptrons 254\r\n Supervised vs. Unsupervised Learning Algorithms 257\r\n Binary vs. Continuous Inputs and Outputs 257\r\nThe Perceptron 257\r\n Perceptron Learning Algorithm 259\r\n Perceptron Implementation 260\r\nLeast-Mean-Square (LMS) Learning 262\r\n LMS Learning Algorithm 262\r\n LMS Implementation 263\r\nLearning with Backpropagation 265\r\n Backpropagation Algorithm 267\r\n Backpropagation Implementation 268\r\n Tuning Backpropagation 274\r\n Training Variants 274\r\n Weight Adjustment Variants 274\r\nProbabilistic Neural Networks 275\r\n PNN Algorithm 276\r\n PNN Implementation 277\r\nOther Neural Network Architectures 281\r\n Time Series Processing Architecture 281\r\n Recurrent Neural Network 283\r\nTips for Building Neural Networks 283\r\n Defining the Inputs 283\r\n Defining the Outputs 284\r\n Choice of Activation Functions 284\r\n Number of Hidden Layers 285\r\n","uuid":"72123125-7e03-4769-bfd2-9f453528a86d"},"_type":"pdf"},{"_id":"BZFSu4IBzLTTH-8HZykE","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":13,"pages":518,"text":"Chapter Summary 285\r\nReferences  285\r\nExercises  285\r\nChapter 9 Neural Networks II 289-328\r\n Unsupervised Learning 289\r\n Hebbian Learning 290\r\n  Hebb’s Rule 291\r\n  Hebb Rule Implementation 292\r\n Simple Competitive Learning 296\r\n  Vector Quantization 297\r\n  Vector Quantization Implementation 298\r\n k-Means Clustering 304\r\n  k-Means Algorithm 305\r\n  k-Means Implementation 307\r\n Adaptive Resonance Theory 313\r\n  ART-1 Algorithm 314\r\n  ART-1 Implementation 316\r\n Hopfield Auto-Associative Model 322\r\n  Hopfield Auto-Associator Algorithm 323\r\n  Hopfield Implementation 324\r\n Summary 327\r\n References 328\r\n Exercises 328\r\nChapter 10 Robotics and AI 329-348\r\n Introduction to Robotics 329\r\n  What is a Robot? 330\r\n  A Sampling from the Spectrum of Robotics 331\r\n  Taxonomy of Robotics 332\r\n   Fixed 333\r\n   Legged 333\r\n   Wheeled 333\r\n   Underwater 333\r\n   Aerial 333\r\n   Other Types of Robots 334\r\n  Hard vs. Soft Robotics 334\r\n Braitenburg Vehicles 334\r\n Natural Sensing and Control 336\r\n Perception with Sensors 337\r\n","uuid":"a206af98-8b1b-46e4-a1ee-929bcc647b3e"},"_type":"pdf"},{"_id":"BpFSu4IBzLTTH-8HZykH","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":14,"pages":518,"text":" Actuation with Effectors 338\r\n Robotic Control Systems 338\r\n Simple Control Architectures 339\r\n  Reactive Control 340\r\n  Subsumption 340\r\n  Other Control Systems 342\r\n Movement Planning 342\r\n  Complexities of Motion Planning 342\r\n  Cell Decomposition 343\r\n  Potential Fields 344\r\n Group or Distributed Robotics 345\r\n Robot Programming Languages 346\r\n Robot Simulators 346\r\n Summary 346\r\n References 346\r\n Resources 347\r\n Exercises 347\r\nChapter 11 Intelligent Agents 349-391\r\n Anatomy of an Agent 350\r\n Agent Properties and AI 351\r\n  Rationale 352\r\n  Autonomous 352\r\n  Persistent 352\r\n  Communicative 352\r\n  Cooperative 353\r\n  Mobile 353\r\n  Adaptive 353\r\n Agent Environments 353\r\n Agent Taxonomies 356\r\n  Interface Agents 356\r\n  Virtual Character Agents 357\r\n  Entertainment Agents 358\r\n  Game Agents 358\r\n  ChatterBots 360\r\n   Eliza and Parry 360\r\n   AIML 361\r\n  Mobile Agents 362\r\n  User Assistance Agent 364\r\n   Email Filtering 364\r\n","uuid":"0b92f7ce-6ec2-447e-a68f-aaeeccc034ea"},"_type":"pdf"},{"_id":"B5FSu4IBzLTTH-8HZykJ","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":15,"pages":518,"text":"   Information Gathering and Filtering 365\r\n   Other User-Assistance Applications 365\r\n  Hybrid Agent 366\r\n Agent Architectures 366\r\n  What is Architecture? 366\r\n  Types of Architectures 367\r\n   Reactive Architectures 367\r\n   Deliberative Architectures 368\r\n   Blackboard Architectures 369\r\n   BDI Architecture 370\r\n   Hybrid Architectures 371\r\n   Mobile Architectures 371\r\n  Architecture Description 372\r\n   Subsumption Architecture (Reactive) 372\r\n   Behavior Networks (Reactive) 373\r\n   ATLANTIS (Deliberative) 375\r\n   Homer (Deliberative) 376\r\n   BB1 (Blackboard) 377\r\n   Open Agent Architecture (Blackboard) 377\r\n   Procedural Reasoning System (BDI) 378\r\n   Aglets (Mobile) 379\r\n   Messengers (Mobile) 380\r\n   SOAR (Hybrid) 382\r\n Agent Languages 382\r\n  Telescript 382\r\n  Aglets 383\r\n  Obliq 384\r\n  Agent TCL 384\r\n  Traditional Languages 385\r\n Agent Communication 385\r\n  Knowledge Query and Manipulation Language (KQML) 385\r\n  FIPA Agent Communication Language 388\r\n  Extensible Markup Language (XML) 388\r\n Summary 389\r\n Resources 389\r\n References 390\r\n Exercises  391\r\nChapter 12 Biologically Inspired and Hybrid Models 393-432\r\n Cellular Automata 393\r\n","uuid":"0c353315-d0d9-41d0-98d2-b7a4fbf15bbe"},"_type":"pdf"},{"_id":"CJFSu4IBzLTTH-8HZykM","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":16,"pages":518,"text":"  One Dimensional CA 394\r\n  Two Dimensional CA 395\r\n  Conway Application 396\r\n  Turing Completeness 398\r\n  Emergence and Organization 398\r\n Artificial Immune Systems 398\r\n  Self-Management Capabilities 399\r\n  Touchpoints 400\r\n  Touchpoint Autonomic Managers 400\r\n  Orchestrating Autonomic Managers 401\r\n  Integrated Management Console 401\r\n  Autonomic Summary 402\r\n Artificial Life 402\r\n  Echo 403\r\n  Tierra 403\r\n  Simulated Evolution 403\r\n   Environment 403\r\n   The Bug (or Agent) 404\r\n  Variations of Artificial Life 408\r\n  Lindenmayer Systems 408\r\n Fuzzy Logic 410\r\n  Introduction to Fuzzy Logic 410\r\n  Fuzzy Logic Mapping 411\r\n  Fuzzy Logic Operators 414\r\n  Fuzzy Control 415\r\n Evolutionary Neural Networks 416\r\n  Genetically Evolved Neural Networks 416\r\n   Simulation Evolution Example 419\r\n Ant Colony Optimization 423\r\n  Traveling Salesman Problem 423\r\n   Path Selection 425\r\n   Pheromone Intensification 425\r\n   Pheromone Evaporation 426\r\n   New Tour 426\r\n  Sample Usage 426\r\n  ACO Parameters 430\r\n Affective Computing 430\r\n  Characterizing Human Emotion 430\r\n  Synthesizing Emotion 431\r\n Resources 432\r\n","uuid":"432ac7e5-b4ea-47db-a65d-8ab3c9335953"},"_type":"pdf"},{"_id":"CZFSu4IBzLTTH-8HZykO","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":17,"pages":518,"text":"Chapter 13 The Languages of AI 433-483\r\n Language Taxonomy 433\r\n  Functional Programming 434\r\n  Imperative Programming 437\r\n  Object Oriented Programming 438\r\n  Logic Programming 441\r\n Languages of AI 442\r\n  The LISP Language 443\r\n   The History of the LISP Language 443\r\n   Overview of the LISP Language 444\r\n    Data Representation 444\r\n    Simple Expressions 444\r\n    Predicates 445\r\n    Variables 445\r\n    List Processing 445\r\n    Programs as Data 447\r\n    Conditions 447\r\n    Functions in LISP 448\r\n   LISP Summary 451\r\n  The Scheme Language 451\r\n   History of Scheme 452\r\n   Overview of the Scheme Language 452\r\n    Data Representation 452\r\n    Simple Expressions 452\r\n    Predicates 453\r\n    Variables 453\r\n    List Processing 454\r\n    Conditions 455\r\n    Iteration and Maps 456\r\n    Procedures in Scheme 457\r\n   Scheme Summary 460\r\n  The POP-11 Language 460\r\n   History of POP-11 460\r\n   Overview of the POP-11 Language 460\r\n    Data Representation 460\r\n    Predicates 461\r\n    Simple Expressions 461\r\n    Variables 462\r\n    List Processing 462\r\n    Conditions 463\r\n","uuid":"4894208e-0b74-414e-8984-a41c1e6ec246"},"_type":"pdf"},{"_id":"CpFSu4IBzLTTH-8HZykR","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":18,"pages":518,"text":"    Iteration and Maps 464\r\n    Pattern Matching 465\r\n    Procedures in POP-11 465\r\n   POP-11 Summary 468\r\n  Prolog 468\r\n   History of Prolog 469\r\n   Overview of the Prolog Language 469\r\n    Data Representation 469\r\n    List Processing 470\r\n    Facts, Rules, and Evaluation 471\r\n    Arithmetic Expressions 478\r\n   Prolog Summary 480\r\n Other Languages 480\r\n Chapter Summary 481\r\n References 481\r\n Resources 482\r\n Exercises 482\r\nAbout the CD-ROM 485\r\nIndex 487-498\r\n","uuid":"400ed829-8390-409c-86c1-38e35181e5af"},"_type":"pdf"},{"_id":"C5FSu4IBzLTTH-8HZykT","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":19,"pages":518,"text":"\r\n","uuid":"6a4f8e42-22f8-4c2e-ad96-f9d66ed791e4"},"_type":"pdf"},{"_id":"DJFSu4IBzLTTH-8HZykW","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":20,"pages":518,"text":"The history of AI is interesting all by itself.  It’s a modern-day drama, \r\nfilled with excitement and anticipation, discovery, and disappointment. \r\nFrom over-promises of early (and later) AI research, to fears of the \r\nunknown from the general public, AI’s history is worthy of study by itself. \r\nIn this chapter, we’ll explore AI’s tumultuous history and also provide a \r\nsummary introduction to each of the chapters of this book.\r\nWHAT IS INTELLIGENCE?\r\nTo build software that is deemed intelligent, it’s helpful to begin with a \r\ndefinition of intelligence. Intelligence can be simply defined as a set of \r\nproperties of the mind. These properties include the ability to plan, solve \r\nproblems, and in general, reason.  A simpler definition could be that \r\nintelligence is the ability to make the right decision given a set of inputs and \r\na variety of possible actions.\r\nUsing this simple definition of intelligence (making the right decision), \r\nwe can apply this not only to humans, but also to animals that exhibit rational \r\nbehavior.  But the intelligence that is exhibited by human beings is much \r\nmore complex than that of animals.  For example, humans have the ability \r\nC h a p t e r 1 THE HISTORY OF AI\r\n","uuid":"cf0421f8-316a-4911-a1e9-45acd7e48216"},"_type":"pdf"},{"_id":"DZFSu4IBzLTTH-8HZykY","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":21,"pages":518,"text":"2 Artificial Intelligence\r\nto communicate with language, but so do some animals.  Humans can also \r\nsolve problems, but the same can be said of some animals.  One difference \r\nthen is that humans embody many aspects of intelligence (the ability to \r\ncommunicate, solve problems, learn and adapt) where animals typically \r\nembody a small number of intelligent characteristics, and usually at a much \r\nlower level than humans.\r\nWe can use the same analogy on AI applied to computer systems. For \r\nexample, it’s possible to build an application that plays a world-class game of \r\nChess, but this program knows nothing of the game of Checkers, nor how to \r\nmake a good cup of tea. A data mining application can help identify fraud, \r\nbut can’t navigate a complex environment. From this perspective, the most \r\ncomplex and intelligent applications can be deemed intelligent from one \r\nperspective, but lack even the simplest intelligence that can be seen in the \r\nleast intelligent of animals.\r\nNOTE  Famed author Isaac Asimov once wrote about his experience with \r\naptitude tests in the army. In the army, he scored well above the norm. \r\nBut what he realized was that he could score well on tests that were \r\ndeveloped by others that shared his academic bents. He opined that if \r\nthe tests were developed by people involved in auto repair, he would have \r\nscored very poorly. The issue being that tests are developed around a \r\ncore of expertise, and scoring poorly on one doesn’t necessarily indicate \r\na lack of intelligence.\r\nTHE SEARCH FOR MECHANICAL INTELLIGENCE\r\nHistory is filled with stories of the creation of intelligent machines. In the \r\n800s BC, the Iliad described the winged Talos, a bronze automaton forged by \r\nHephaestus to protect Crete. The inner workings of Talos weren’t described, \r\nexcept that he was bronze, and filled with ichor (or a Greek god’s blood). A \r\nmore recent example is Mary Shelley’s Frankenstein, in which the scientist \r\nrecreates life from old. In 1921, Karel Capek’s play “Rossum’s Universal\r\nRobots” introduced the concept of cheap labor through robotics. \r\nBut one of the most interesting applications of artificial intelligence, \r\nin a non-robitic form, was that of the HAL 9000 introduced by Arthur C. \r\nClark in his his novel “2001: A Space Odyssey.” HAL was a sentient artificial \r\nintelligence that occupied the Discovery spaceship (en route to Jupiter). \r\nHAL had no physical form, but instead managed the spaceship’s systems, \r\nvisually watched the human occupants through a network of cameras, and \r\n","uuid":"97eda7a5-904c-45e7-93bd-7a9c8891f2dd"},"_type":"pdf"},{"_id":"DpFSu4IBzLTTH-8HZykb","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":22,"pages":518,"text":"The History of AI 3\r\ncommunicated with them in a normal human voice. The moral behind the \r\nstory of HAL was one of modern-day programming. Software does exactly \r\nwhat one tells it to do, and can make incorrect decisions trying to focus on \r\na single important goal. HAL obviously was not created with Isaac Asimov’s \r\nthree laws of robotics in mind.\r\nTHE VERY EARLY DAYS (THE EARLY 1950s)\r\nWhile the term artificial intelligence had not yet been conceived, the 1950s \r\nwere the very early days of AI. Early computer systems were being built, and \r\nthe ideas of building intelligent machines were beginning to form.\r\nAlan Turing\r\nIn 1950 it was Alan Turing who asked whether a machine could think. \r\nTuring not long before had introduced the concept of his universal abstract \r\nmachine (called the Turing Machine) that was simple and could solve any \r\nmathematical problem (albiet with some complexity). Building on this idea, \r\nTuring wondered that if a computer’s response were indistinguishable from \r\na human, then the computer could be considered a thinking machine. The \r\nresult of this experiment is called the Turing Test. \r\nIn the Turing test, if the machine could fool a human into thinking that \r\nit was also human, then it passed the intelligence test. One way to think of \r\nthe Turing test is by communicating to the other agent through a keyboard. \r\nQuestions are asked of the peer through written text, and responses are \r\nprovided through the terminal. This test provides a way to determine if \r\nintelligence was created. Considering the task at hand, not only must the \r\nintelligent peer contain the necessary knowledge to have an intelligent \r\nconversation, it must be able to parse and understand natural language and \r\ngenerate natural language responses. The questions may involve reasoning \r\nskills (such as problem solving), so mimicking humans would be a feat!\r\nAn important realization of Turing during this period was the need to \r\nstart small and grow intelligence, rather than expecting it to materialize. \r\nTuring proposed what he called the Child Machine in which a lesser \r\nintelligent agent would be created and then subjected to a course of \r\neducation. Rather than assume that we could build an adult intelligence, \r\nwe would build a child intelligence first and then inject it with knowledge. \r\nThis idea of starting small and at lower levels corresponds with later ideas \r\nof so-called “scruffy” thinkers. The human brain is complex and not fully \r\n","uuid":"ecd277d6-1d90-4bdd-9ed7-fd886b9df4c6"},"_type":"pdf"},{"_id":"D5FSu4IBzLTTH-8HZyke","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":23,"pages":518,"text":"4 Artificial Intelligence\r\nunderstood, instead of striving to imitate this, why not start smaller at the \r\nchild (or even smaller organism) and work our way up? Turing called this the \r\nblank sheets argument. A child is like a notebook that’s full of blank sheets, \r\nbut is a mechanism by which knowledge is stored.\r\nAlan Turing’s life ended at a young age, but he’s considered the founder \r\nof the field of AI (even though the moniker would not be applied for another \r\nsix years).\r\nAI, Problem Solving, and Games\r\nSome of the earliest applications of AI focused on games and general \r\nproblem solving. At this time, creating an intelligent machine was based on \r\nthe belief that the machine would be intelligent if it could do something that \r\npeople do (and perhaps find difficult).\r\nNOTE  In 1950, Claude Shannon proposed that the game of Chess was \r\nfundamentaly a search problem. In fact, he was correct, but brute force \r\nsearch isn’t truly practical for the search space that exists with Chess. \r\nSearch, heuristics, and a catalog of opening and ending moves provides \r\na faster and more efficient way to play Chess. Shannon’s seminal paper \r\non computer Chess produced what is called the Shannon number, or \r\n10^120, which represents the lower bound of the game tree complexity \r\nof Chess. [Shannon 1950]\r\nThe first AI program written for a computer was called “The Logic \r\nTheorist.” It was developed in 1956 by Allen Newell, Herbert Simon, and J. \r\nC. Shaw to find proofs for equations. [Newell 1956] What was most unique \r\nabout this program is that it found a better proof than had existed before for \r\na given equation. In 1957, Simon and Newell built on this work to develop \r\nthe General Problem Solver (GPS). The GPS used means-end analysis to \r\nsolve problems, but in general was restricted to toy problems.\r\nLike complex math, early AI researchers believed that if a computer \r\ncould solve problems that they thought were complex, then they could build \r\nintelligent machines. Similarly, games provided an interesting testbed for the \r\ndevelopment of algorithms and techniques for intelligent decision making.\r\nIn the UK at Oxford University in the early 1950s, researchers developed \r\ngame-playing programs for two complex games. Christopher Strachey \r\ndeveloped a Checkers playing program on the Ferranti Mark I. By 1952, his \r\nprogram could play a reasonable game of Checkers. Dietrich Prinz developed \r\na program, again for the Ferranti Mark I, that could play Chess (mate-in-two \r\nvariety). His program could search a thousand possible moves, but on this \r\n","uuid":"663e2869-cf08-4986-9a30-46b3d4e6b9a4"},"_type":"pdf"},{"_id":"EJFSu4IBzLTTH-8HZykh","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":24,"pages":518,"text":"The History of AI 5\r\nearly computer, it required significant time and played very slowly.\r\nIn 1952, Arthur Samuel raised the bar for AI programs. His Checkers \r\nplaying program, which ran on the IBM 701, included learning and \r\ngeneralization. What Samuel did with his learning Checkers program was \r\nunique in that he allowed two copies of his program to play one another, \r\nand therefore learn from each other. The result was a program that could \r\ndefeat its creator. By 1962, Samuel’s Checkers program defeated the former \r\nConnecticut Checkers champion.\r\nNOTE  Samuel’s program, and his approach of playing copies against one \r\nanother, is one of the first examples of computing survival of the fittest \r\nand the field which came to be called evolutionary computation.\r\nARTIFICIAL INTELLIGENCE EMERGES AS A FIELD \r\nBy the mid 1950s, AI began to solidify as a field of study. At this point in AI’s \r\nlife, much of the focus was on what is called Strong AI Strong AI is focused \r\non building AI that mimics the mind. The result is a sapient entity with \r\nhuman-like intelligence, self-awareness, and consciousness.\r\nThe Dartmouth AI Summer Research Project\r\nIn 1956, the Dartmouth AI Conference brought about those involved in \r\nresearch in AI: John McCarthy (Dartmouth), Marvin Minsky (Harvard), \r\nNathaniel Rochester (IBM), and Claude Shannon (Bell Telephone \r\nLaboratories) brought together researchers in computers, natural language \r\nprocessing, and neuron nets to Dartmouth College for a month-long session \r\nof AI discussions and research. The Summer research project on AI began:\r\nWe propose that a 2 month, 10 man study of artificial intelligence \r\nbe carried out during the summer of 1956 at Dartmouth College \r\nin Hanover, New Hampshire. The study is to proceed on the basis \r\nof the conjecture that every aspect of learning or any other feature \r\nof intelligence can in principle be so precisely described that a \r\nmachine can be made to simulate it. An attempt will be made to \r\nfind how to make machines use language, form abstractions and \r\nconcepts, solve kinds of problems now reserved for humans, and \r\nimprove themselves. We think that a significant advance can be \r\nmade in one or more of these problems if a carefully selected \r\ngroup of scientists work on it together for a summer.\r\n","uuid":"6fcbf0d1-1773-4332-ace1-ecdcc9871be7"},"_type":"pdf"},{"_id":"EZFSu4IBzLTTH-8HZykj","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":25,"pages":518,"text":"6 Artificial Intelligence\r\nSince then, many AI conferences have been held around the world, \r\nand on a variety of disciplines studied under the AI moniker. In 2006, \r\nDartmouth held the “Dartmouth Artificial Intelligence Conference: The \r\nNext Fifty Years” (informally known as AI@50). The conference was well \r\nattended (even from a few that attended the first conference 50 years prior), \r\nand analyzed AI’s progress and how its challenges relate to those of other \r\nfields of study.\r\nBuilding Tools for AI\r\nIn addition to coining the term artificial intelligence, and bringing together \r\nmajor researchers in AI in his 1956 Dartmouth conference, John McCarthy \r\ndesigned the first AI programming language. LISP was first described by \r\nMcCarthy in his paper titled “Recursive Functions of Symbolic Expressions \r\nand their Computation by Machine, Part I.” The first LISP compiler was \r\nalso implemented in LISP, by Tim Hart and Mike Levin at MIT in 1962 for \r\nthe IBM 704.\r\nThis compiler introduced many advanced features, such as incremental \r\ncompilation. [LISP 2007] McCarthy’s LISP also pioneered many advanced \r\nconcepts now familiar in computer science, such as trees (data structures), \r\ndynamic typing, object-oriented programming, and compiler self-hosting.\r\nLISP was used in a number of early AI systems, demonstrating its \r\nusefulness as an AI language. One such program, called SHRDLU, provides \r\na natural language interface to a table-top world of objects. The program can \r\nunderstand queries about the table-top “world,” reason about the state of \r\nthings in the world, plan actions, and perform some rudimentary learning. \r\nSHRDLU was designed and implemented by Terry Winograd at the MIT \r\nAI Lab on a PDP-6 computer.\r\nLISP, and the many dialects that evolved from it, are still in wide \r\nuse today. Chapter 13 provides an introduction to the languages of AI, \r\nincluding LISP.\r\nThe Focus on Strong AI\r\nRecall that the focus of early AI was in Strong AI. Solving math or logic \r\nproblems, or engaging in dialogue, was viewed as intelligent, while activities \r\nsuch as walking freely in unstable environments (which we do every day) \r\nwere not.\r\nIn 1966, Joseph Weizenbaum of MIT developed a program that parodied \r\na psychologist and could hold an interesting dialogue with a patient. The \r\ndesign of Eliza would be considered simple by today’s standards, but its \r\n","uuid":"cf860ed8-6693-4f89-87c6-93fbab19022f"},"_type":"pdf"},{"_id":"EpFSu4IBzLTTH-8HZykm","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":26,"pages":518,"text":"The History of AI 7\r\npattern-matching abilities, which provided reasonable responses to patient \r\nstatements was real to many people. This quality of the program was \r\ntroubling to Weizenbaum who later became a critic of AI because of its lack \r\nof compassion.\r\nConstrained Applications\r\nWhile much of early AI was Strong-focused, there were numerous applications \r\nthat focused on solving practical problems. One such application was called \r\nthe “Dendral Project,” emerging in 1965 at Stanford University. Dendral was \r\ndeveloped to help organic chemists understand the organization of unknown \r\norganic molecules. It used as its inputs mass spectrometry graphs and a \r\nknowledge base of chemistry, making it the first known expert system.\r\nOther constrained applications in this era include Macsyma, a \r\ncomputer algebra system developed at MIT by Carl Engelman, William \r\nMartin, and Joel Moses. Macsyma was written in MacLisp, a dialect \r\nof LISP developed at MIT. This early mathematical expert system \r\ndemonstrated solving integration problems with symbolic reasoning. \r\nThe ideas demonstrated in Macsyma eventually made their way into \r\ncommercial math applications.\r\nBottom-Up Approaches Emerge\r\nEarly AI focused on a top-down approach to AI, attempting to simulate or \r\nmimic the higher level concepts of the brain (planning, reasoning, language \r\nunderstanding, etc.). But bottom-up approaches began to gain favor in the \r\n1960s, primarily modeling lower-level concepts, such as neurons and learning \r\nat a much lower level. In 1949, Donald Hebb introduced his rule that \r\ndescribes how neurons can associate with one another if they are repeatedly \r\nactive at the same time. The contribution of one cell’s firing to enable another \r\nwill increase over time with persistent firing, leading to a strong relationship \r\nbetween the two (a causal relationship).\r\nBut in 1957, the perceptron was created by Frank Rosenblatt at the \r\nCornell Aeronautical Laboratory. The perceptron is a simple linear classifier \r\nthat can classify data into two classes using an unsupervised learning \r\nalgorithm. The perceptron created considerable interest in neural network \r\narchitectures, but change was not far away.\r\nNOTE  Hebbian learning, perceptrons, and more advanced neural network \r\narchitectures and learning algorithms are covered in the neural network \r\nChapters 8 and 9.\r\n","uuid":"b6236759-26e8-4710-a09e-d067671904cf"},"_type":"pdf"},{"_id":"E5FSu4IBzLTTH-8HZyko","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":27,"pages":518,"text":"8 Artificial Intelligence\r\nAI’S WINTER\r\nPrior to the 1970s, AI had generated considerable interest, and also \r\nconsiderable hype from the research community. Many interesting systems \r\nhad been developed, but these fell quite short of the predictions made by \r\nsome in the community. But new techniques such as neural networks breathed \r\nnew life into this evolving field, providing additional ways for classification and \r\nlearning. But the excitement of neural networks came to an end in 1969 with \r\nthe publication of the mongraph titled “Perceptrons.” This monograph was \r\nwritten by Marvin Minsky and Seymour Papert, strong advocates of Strong (or \r\ntop-down) AI. The authors rightly demonstrated that single-layer perceptrons \r\nwere limited, particularly when confronted with problems that are not linearly \r\nseparable (such as the XOR problem). The result was a steep decline of \r\nfunding into neural network research, and in general, research in AI as a field. \r\nSubsequent research would find that the multi-layer networks solved the linear \r\nseparation problem, but too late for the damage done to AI.\r\nHardware built for AI, such as the LISP machines, also suffered a loss \r\nof interest. While the machines gave way to more general systems (not \r\nnecessarily programmed in LISP), the functional languages like LISP \r\ncontinued to attract attention. Popular editors such as EMACS (developed \r\nduring this period) still support a large user community with a scripting shell \r\nbased on LISP.\r\nResults-Oriented Applications\r\nWhile there was a reduction in focus and spending in AI research in the \r\n1970s, AI development continued but in a more focused arena. Applications \r\nthat showed promise, such as expert systems, rose as one of the key \r\ndevelopments in this era. \r\nOne of the first expert systems to demonstrate the power of rules-based \r\narchitectures was called MYCIN, and was developed by Ted Shortliffe \r\nfollowing his dissertation on the subject while at Stanford (1974). MYCIN \r\noperated in the field of medical diagnosis, and demonstrated knowledge \r\nrepresentation and inference. Later in this decade, another dissertation at \r\nStanford by Bill VanMelles built on the MYCIN architecture and serves as a \r\nmodel for the expert system shell (still in use today). In Chapter 5 we’ll provide \r\nan introduction to the representation of knowledge and inference with logic.\r\nOther results-oriented applications included those focused on natural \r\nlanguage understanding. The goal of systems in this era was in the \r\ndevelopment of intelligent question answering systems. To understand a \r\nquestion stated in natural language, the question must first be parsed into \r\n","uuid":"bcf2e7db-9f02-4063-999d-75253e15400e"},"_type":"pdf"},{"_id":"FJFSu4IBzLTTH-8HZykr","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":28,"pages":518,"text":"The History of AI 9\r\nits fundamental parts. Bill Woods introduced the idea of the Augmented \r\nTransition Network (or ATN) that represents formal languages as augmented \r\ngraphs. From Eliza in the 1960s to ATNs in the 1970s, Natural Language \r\nProcessing (NLP) and Natural Language Understanding (NLU) continues \r\ntoday in the form of chatterbots.\r\nAdditional AI Tools Emerge\r\nJohn McCarthy introduced the idea of AI-focused tools in the 1950s with the \r\ndevelopment of the LISP language. Expert systems and their shells continued \r\nthe trend with tools for AI, but another interesting development that in a \r\nway combined the two ideas resulted from the Prolog language. Prolog was \r\na language built for AI, and was also a shell (for which expert systems could \r\nbe developed). Prolog was created in 1972 by Alain Colmeraur and Phillipe \r\nRoussel based on the idea of Horn clauses. Prolog is a declarative high-level \r\nlanguage based on formal logic. Programs written in Prolog consist of facts and \r\nrules that reason over those facts. You can find more information on Prolog in \r\nChapter 5 Knowledge Representation and Chapter 13, The Languages of AI. \r\nNeat vs Scruffy Approaches\r\nA split in AI, its focus, and basic approaches was also seen during this \r\nperiod. Traditional, or top-down AI (also called Good-Old-Fashioned-AI, \r\nor GOFAI for short) continued during this period but new approaches \r\nbegan to emerge that looked at AI from the bottom-up. These approaches \r\nwere also labeled Neat and Scruffy approaches segregating them into their \r\nrepresentative camps. Those in the neat camp favored formal approaches to \r\nAI that were pure and provable. But those in the scruffy camp used methods \r\nless provable but still yielding useful and significant results. A number of \r\nscruffy approaches to AI that became popular during this period included \r\ngenetic algorithms (modeling natural selection for optimization) and neural \r\nnetworks (modeling brain behavior from the neuron up).\r\nGenetic algorithms became popularized in the 1970s due to the work \r\nof John Holland and his students at the University of Michigan. Holland’s \r\nbook on the topic continues to be a useful resource. Neural networks, while \r\nstagnant for a time after the publication of “Perceptrons,” were revived \r\nwith Paul John Werbos’ creation of the backpropagation algorithm. This \r\nalgorithm remains the most widely used supervised learning algorithm for \r\ntraining feedforward neural networks. You can learn more about genetic \r\nalgorithms and evolutionary computation in Chapter 3 and neural networks \r\nin Chapters 8, and 9.\r\n","uuid":"6c97228f-cedb-4c8a-b0a2-719e7b928c5e"},"_type":"pdf"},{"_id":"FZFSu4IBzLTTH-8HZyky","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":29,"pages":518,"text":"10 Artificial Intelligence\r\nAI RE-EMERGES\r\nJust as spring always follows the winter, AI’s winter would eventually end \r\nand bring new life into the field (starting in the mid to late 1980s). The \r\nre-emergence of AI had significant differences from the early days. Firstly, \r\nthe wild predictions of creating intelligent machines were for the most part \r\nover. Instead, researchers and AI practitioners focused on specific goals \r\nprimarily in the weak aspects of AI (as opposed to Strong AI). Weak AI \r\nfocused on solving specific problems, compared to Strong AI, whose goal \r\nwas to emulate the full range of human cognitive capabilities. Secondly, \r\nthe field of AI broadened to include many new types of approaches, \r\nfor example, the biologically inspired approaches such as Ant Colony \r\nOptimization (ACO).\r\nThe Silent Return\r\nAn interesting aspect of AI’s return was that it occurred silently. Instead of \r\nthe typical claims of Strong AI, weak algorithms found use in a variety of \r\nsettings. Fuzzy logic and fuzzy control systems were used in a number of \r\nsettings, including camera auto-focus, antilock braking systems as well as \r\nplaying a part in medical diagnosis. Collaborative filtering algorithms found \r\ntheir way into product recommendation at a popular online bookseller, and \r\npopular Internet search engines use AI algorithms to cluster search results \r\nto help make finding what you need easier.\r\nThe silent return follows what Rodney Brooks calls the “AI effect.” AI \r\nalgorithms and methods transition from being “AI” to standard algorithms \r\nand methods once they become practically useful. The methods described \r\nabove are one example, another is speech recognition. The algorithms \r\nbehind recognizing the sounds of speech and translating them into symbols \r\nwere once described within the confines of AI. Now these algorithms are \r\ncommonplace, and the AI moniker has long since passed. Therefore, the AI \r\neffect has a way of diminishing AI research, as the heritage of AI research \r\nbecomes lost in the practical application of the methods.\r\nMessy and Scruffy Approaches Take Hold\r\nWith AI’s resurgence came different views and approaches to AI and problem \r\nsolving with AI algorithms. In particular, the scruffy approaches became \r\nmore widespread and the algorithms became more applicable to real-world \r\nproblems. Neural networks continued to be researched and applied, and new \r\nalgorithms and architectures resulted. Neural networks and genetic algorithms \r\n","uuid":"65fc1911-2c5c-483c-ad00-ad95cdda1ff6"},"_type":"pdf"},{"_id":"FpFSu4IBzLTTH-8HZyk1","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":30,"pages":518,"text":"The History of AI 11\r\ncombined to provide new ways to create neural network architectures that not \r\nonly solved problems, but did so in the most efficient ways. This is because the \r\nsurvival of the fittest features of the genetic algorithm drove neural network \r\narchitectures to minimize for the smallest network to solve the given problem \r\nat hand. The use of genetic algorithms also grew in a number of other areas \r\nincluding optimization (symbolic and numerical), scheduling, modeling \r\nand many others. Genetic algorithms and neural networks (supervised and \r\nunsupervised) are covered in Chapters 7, 8, and 9.\r\nOther bottom-up and biologically inspired approaches followed in the \r\n1990s and beyond. In early 1992, for example, Marco Dorigo introduced \r\nthe idea of using stigmergy (indirect communication in an environment, in \r\nthis case, pheromones). Dorigo’s use of stigmergy was applied to a variety \r\nof problems. Ant Colony Optimization (or ACO) is demonstrated with the \r\ntraveling salesman problem in Chapter 12.\r\nAlso emerging out of the messy approaches to AI was a new field \r\ncalled Artificial Life. Artificial Life research studies the processes of life \r\nand systems related to life through a variety of simulations and models. \r\nIn addition to modeling singular life, ALife also simulates populations of \r\nlifeforms to help understand not only evolution, but also the evolution of \r\ncharacteristics such as language. Swarm intelligence is another aspect of \r\nthis that grew from ALife research. ALife is interesting in the context of AI \r\nbecause it can use a number of AI methods such as neural networks (as the \r\nneuro-controller of the individuals in the population) as well as the genetic \r\nalgorithm to provide the basis for evolution. This book provides a number \r\nof demonstrations of ALife both in the context of genetic algorithms and \r\nneural networks.\r\nNOTE  One of the earliest simulation environments that demonstrated artificial \r\nlife was the “game of life” created by John Conway. This was an example \r\nof a cellular automaton, and is explored later.\r\nAnother bottom-up approach that evolved during AI’s re-emergence used \r\nthe human immune system as inspiration. Artificial Immune Systems (or AIS) \r\nuse principles of the immune system and the characteristics that it exhibits \r\nfor problem solving in the domains of optimization, pattern recognition, and \r\ndata mining. A very novel application of AIS is in computational security. \r\nThe human body reacts to the presence of infections through the release of \r\nantibodies which destroy those infectious substances. Networks of computers \r\ncan perform the same function, for example, in the domain of network \r\nsecurity. If a software virus is found on a computer within a given network, \r\n","uuid":"63d1b243-9048-458c-9a0f-36cfb70f6988"},"_type":"pdf"},{"_id":"F5FSu4IBzLTTH-8HZyk4","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":31,"pages":518,"text":"12 Artificial Intelligence\r\nother “antibody” programs can be dispatched to contain and destroy those \r\nviruses. Biology continues to be a major source of inspiration for solutions \r\nto many types of problems.\r\nAgent Systems\r\nAgents, which are also referred to as intelligent agents or software agents, are \r\na very important element of modern-day AI. In many ways, agents are not an \r\nindependent aspect of but instead a vehicle for AI applications. Agents are \r\napplications that exhibit characteristics of intelligent behavior (such as learning \r\nor classification), but are not in themselves AI techniques. There also exists \r\nother agent-based methods such as agent-oriented computing and multi-agent \r\nsystems. These apply the agent metaphor for solving a variety of problems.\r\nOne of the most popular forms of intelligent agents is “agency” \r\napplications. The word agency is used because the agent represents a user \r\nfor some task that it performs for the user. An example includes a scheduling \r\napplication. Agents representing users intelligently negotiate with one \r\nanother to schedule activities given a set of constraints for each user.\r\nThe concept of agents has even been applied to the operation of a \r\ndeepspace spacecraft. In 1999 NASA integrated what was called the “Remote \r\nAgent” into the Deep Space 1 spacecraft. Deep Space 1’s goal was to test a \r\nnumber of high-risk technologies, one of which was an agent that was used to \r\nprovide autonomy to the spacecraft for limited durations of time. The Remote \r\nAgent employed planning techniques to autonomously schedule experiments \r\nbased on goals defined by ground operators. Under constrained conditions, the \r\nRemote Agent succeeded in proving that an intelligent agent could be used to \r\nautonomously manage a complicated probe and satisfy predefined objectives.\r\nToday you’ll find agents in a number of areas, including distributed systems. \r\nMobile agents are independent agents that include autonomy and the ability \r\nto travel amongst nodes of a network in order to perform their processing. \r\nInstead of the agent communicating with another agent remotely, the mobile \r\nagent can travel to the other agent’s location and communicate with it directly. \r\nIn disconnected network situations, this can be very beneficial. You can learn \r\nmore about intelligent agents (including mobile agents) in Chapter 11.\r\nAI INTER-DISCIPLINARY R&D\r\nIn many cases, AI research tends to be fringe research, particularly when \r\nit’s focused on Strong AI. But what’s notable about research in AI is that \r\nthe algorithms tend to find uses in many other disciplines beyond that of \r\n","uuid":"a1d4ab88-2f4e-4236-9aa6-f46b7261686c"},"_type":"pdf"},{"_id":"GJFSu4IBzLTTH-8HZyk7","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":32,"pages":518,"text":"The History of AI 13\r\nAI. AI research is by no means pure research, but its applications grow well \r\nbeyond the original intent of the research. Neural networks, data mining, \r\nfuzzy logic, and Artificial Life (for example) have found uses in many other \r\nfields. Artificial Life is an interesting example because the algorithms and \r\ntechniques that have resulted from research and development have found \r\ntheir way into the entertainment industry (from the use of swarming in \r\nanimated motion pictures to the use of AI in video games).\r\nRodney Brook’s has called this the AI effect, suggesting that another \r\ndefinition for AI is “almost implemented.” This is because once an AI \r\nalgorithm finds a more common use, it’s no longer viewed as an AI algorithm \r\nbut instead just an algorithm that’s useful in a given problem domain.\r\nSYSTEMS APPROACH\r\nIn this book, the majority of the algorithms and techniques are studied \r\nfrom the perspective of the systems approach. This simply means that the \r\nalgorithm is explored in the context of inputs and outputs. No algorithm is \r\nuseful in isolation, but instead from the perspective of how it interacts with \r\nits environment (data sampling, filtering, and reduction) and also how it \r\nmanipulates or alters its environment. Therefore, the algorithm depends \r\non an understanding of the environment and also a way to manipulate the \r\nenvironment. This systems approach illustrates the practical side of artificial \r\nintelligence algorithms and techniques and identifies how to ground the \r\nmethod in the real world (see Figure 1.1).\r\nAs an example, one of the most interesting uses of AI today can be found in \r\ngame systems. Strategy games, for example, commonly occupy a map with two \r\nor more opponents. Each opponent competes for resources in the environment \r\nin order to gain the upper hand over the other. While collecting resources, \r\neach opponent can schedule the development of assets to be used to defeat the \r\nother. When multiple assets exist for an opponent (such as a military unit), they \r\ncan be applied in unison, or separately to lay siege on another opponent.\r\nWhere strategy games depend on a higher-level view of the environment \r\n(such as would be viewed from a general), first-person shooter games \r\n(FPS) take a lower-level view (from that of a soldier). An agent in an FPS \r\ndepends most often on its view of the battlefield. The FPS agent’s view of the \r\nenvironment is at a much lower level, understanding cover, objectives, and \r\nlocal enemy positions. The environment is manipulated by the FPS agent \r\nthrough its own movement, attacking or defending from enemies (through \r\nfinding cover), and possibly communicating with other agents.\r\n","uuid":"edc3d579-7043-4ad3-9644-747cf21c9958"},"_type":"pdf"},{"_id":"GZFSu4IBzLTTH-8HZyk-","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":33,"pages":518,"text":"14 Artificial Intelligence\r\nAn obvious example of the systems approach is in the field of robotics. \r\nMobile robots, for example, utilize an array of sensors and effects that make \r\nup the physical robot. At the core of the robot is one or more algorithms \r\nthat yield rational behavior.\r\nFIGURE 1.1 The systems approach to Artificial Intelligence.\r\n","uuid":"d0a68c68-2f92-4a00-973e-5a4d30051cfc"},"_type":"pdf"},{"_id":"GpFSu4IBzLTTH-8HZylA","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":34,"pages":518,"text":"The History of AI 15\r\nIn each case, the AI algorithm that’s chosen is the core of an agent’s \r\nsensors (inputs) and effectors (outputs). For this reason, the algorithm \r\ncan’t truly be useful or understood unless it’s considered from its place in \r\nthe environment.\r\nOVERVIEW OF THIS BOOK\r\nThis book covers a wide range of AI techniques, each segmented \r\nappropriately into their particular genre. The following chapter summaries \r\npresent the ideas and methods that are explored.\r\nUninformed Search\r\nIn the early days of AI, AI was a search, whether search involved looking for a \r\nplan, or through the various moves that are possible (and subsequent moves) \r\nin a game of Checkers. In this chapter on uninformed (or blind) search, \r\nthe concept of search in various spaces is introduced, the representation \r\nof spaces for search, and then the various popular algorithms used in blind \r\nsearch are explored. This includes depth-first, breadth-first, uniform-cost-\r\nsearch, and others.\r\nInformed Search\r\nInformed search is an evolution of search that applies heuristics to the search \r\nalgorithm, given the problem space, to make the algorithm more efficient. \r\nThis chapter covers best-first, a star, hill climbing, simulated annealing, tabu \r\nsearch, and constraint satisfaction.\r\nAI and Games\r\nOne of the earliest uses of blind and informed search was in the application to \r\ngames. Games such as Checkers and Chess were believed to be an intelligent \r\nactivity, and if a computer could be endowed with the ability to play a game \r\nand win against a human opponent, it could be considered intelligent. \r\nSamuel’s Checkers program demonstrated a program that could defeat its \r\ncreator, and while a feat, this experiment did not produce an intelligent \r\ncomputer except within the domain of Checkers. This chapter explores \r\ntwo-player games and the core of many game-playing systems, the minimax \r\nalgorithm. A variety of games are then discussed, from the classical games \r\nsuch as Chess, Checkers, and Go to video game AI, exploring movement, \r\nbehavior, team, and real-time strategy AI.\r\n","uuid":"52cc76b5-c29b-467a-b017-f420ced78541"},"_type":"pdf"},{"_id":"G5FSu4IBzLTTH-8HZylD","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":35,"pages":518,"text":"16 Artificial Intelligence\r\nKnowledge Representation\r\nKnowledge representation has a long history in AI, particularly in \r\nStrong AI research. The goal behind knowledge representation is to find \r\nabstractions for knowledge that result in a base of knowledge that’s useful \r\nto a given application. For example, knowledge must be represented in \r\na way that makes it easy for a computer to reason with it and understand \r\nthe relationships between elements of the knowledge base. This chapter \r\nwill provide an introduction to a number of fundamental knowledge \r\nrepresentation techniques as well as introduce the ideas behind predicate \r\nand first-order logic to reason with knowledge.\r\nMachine Learning\r\nMachine learning is best described as learning from example. Machine \r\nlearning incorporates a variety of methods such as supervised and \r\nunsupervised learning. In supervised learning, a teacher is available to \r\ndefine correct or incorrect responses. Unsupervised learning differs in that \r\nno teacher is present. (Instead, unsupervised learning learns from the data \r\nitself by identifying its) relationships. This chapter provides an introduction \r\nto machine learning, and then explores a number of machine learning \r\nalgorithms such as decision trees and nearest neighbor learning.\r\nEvolutionary Computation\r\nEvolutionary computation introduced the idea of scruffy approaches to AI. \r\nInstead of focusing on the high level, trying to imitate the behavior of the \r\nhuman brain, scruffy approaches start at a lower level trying to recreate \r\nthe more fundamental concepts of life and intelligence using biological \r\nmetaphors. This chapter covers a number of the evolutionary methods \r\nincluding genetic algorithms, genetic programming, evolutionary strategies, \r\ndifferential evolution, and particle swarm optimization.\r\nNeural Networks I\r\nWhile neural networks are one of the earliest (and more controversial) \r\ntechniques, they remain one of the most useful. The attack on neural \r\nnetworks severely impacted AI funding and research, but neural \r\nnetworks re-emerged from AI’s winter as a standard for classification and \r\nlearning. This chapter introduces the basics of neural networks, and then \r\nexplores the supervised neural network algorithms (least-mean-squares, \r\nbackpropagation, probabilistic neural networks, and others). The chapter \r\n","uuid":"9182587d-fc91-4d7e-8359-b5756f3ff525"},"_type":"pdf"},{"_id":"HJFSu4IBzLTTH-8HZylF","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":36,"pages":518,"text":"The History of AI 17\r\nends with a discussion of neural network characteristics and ways to tune \r\nthem given the problem domain.\r\nNeural Networks II\r\nWhere the previous chapter explored supervised neural network \r\nalgorithms, this chapter provides an introduction to the unsupervised \r\nvariants. Unsupervised algorithms use the data itself to learn without \r\nthe need for a “teacher.” This chapter explores unsupervised learning \r\nalgorithms, including Hebbian learning, Simple Competitive Learning, \r\nk-Means Clustering, Adaptive Resonance Theory, and the Hopfield auto-\r\nassociative model.\r\nIntelligent Agents\r\nIntelligent (or Software) Agents are one of newest techniques in the AI \r\narsenal. In one major definition, agents are applications that include the \r\nconcept of “agency.” This means that those applications represent a user and \r\nsatisfy the goals of the task autonomously without further direction from the \r\nuser. This chapter on intelligent agents will introduce the major concepts \r\nbehind intelligent agents, their architectures and applications.\r\nBiologically Inspired and Hybrid Models\r\nAI is filled with examples of the use of biological metaphors, from early \r\nwork in neural networks to modern-day work in artificial immune systems. \r\nNature has proven to be a very worthy teacher for complex problem \r\nsolving. This chapter presents a number of techniques that are both \r\nbiologically inspired as well as hybrid (or mixed) models of AI. Methods \r\nsuch as artificial immune systems, simulated evolution, Lindenmayer \r\nsystems, fuzzy logic, genetically evolved neural networks, and ant colony \r\noptimization are explored, to name a few.\r\nLanguages of AI\r\nWhile most people think of LISP when considering the languages of AI, \r\nthere have been a large number of languages developed specifically for AI \r\napplication development. In this chapter, a taxonomy of computer languages \r\nis presented followed by short examples (and advantages) of each. Then a \r\nnumber of AI-specific languages are investigated, exploring their history and \r\nuse through examples. Languages explored include LISP, Scheme, POP-11, \r\nand Prolog.\r\n","uuid":"032dfe48-38a0-4598-a83d-f332b472ebf4"},"_type":"pdf"},{"_id":"HZFSu4IBzLTTH-8HZylI","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":37,"pages":518,"text":"18 Artificial Intelligence\r\nCHAPTER SUMMARY\r\nThe history of AI is a modern-day drama. It’s filled with interesting \r\ncharacters, cooperation, competition, and even deception. But outside of \r\nthe drama, there has been exceptional research and in recent history an \r\napplication of AI’s ideas in a number of different settings. AI has finally left \r\nthe perception of fringe research and entered the realm of accepted research \r\nand practical development.\r\nREFERENCES\r\n[LISP 2007] Wikipedia “Lisp (programming language)”, 2007.\r\nAvailable online at http://en.wikipedia.org/wiki/Lisp_%28programming_\r\nlanguage%29 \r\n[Newell 1956] Newell, A., Shaw, J.C., Simon, H.A “Emperical Explorations of \r\nthe Logic Theory Machine: A Case Study in Heuristics,” in Proceedings \r\nof the Western Joint Computer Conference, 1956.\r\n[Shannon 1950] Shannon, Claude, “Programming a Computer for Playing \r\nChess,” Philisophical Magazine 41, 1950.\r\nRESOURCES\r\nRayman, Marc D., et al “Results from the Deep Space 1 Technology \r\nValidation Mission,” 50th International Astronomical Congress, \r\nAmsterdam, The Netherlands, 1999. \r\nde castr, Leandro N., Timmis, Jonathan Artificial Immune Systems: A New \r\nComputational Intelligence Approach Springer, 2002.\r\nHolland, John Adaptation in Natural and Artificial Systems. University of \r\nMichigan Press, Ann Arbor, 1975.\r\nMcCarthy, John “Recursive Functions of Symbolic Expressions and their \r\nComputation by Machine (Part I),” Communications of the ACM, April \r\n1960. \r\nShortliffe, E.H. “Rule-based Exper Systems: The Mycin Experiments of the \r\nStanford Heuristic Programming Project,” Addison-Wesley, 1984.\r\nWinograd, Terry “Procedures as a Representation for Data in a Computer \r\nProgram for Understanding Natural Language,” MIT AI Technical \r\nReport 235, February 1971.\r\nWoods, William A. “Transition Network Grammars for Natural Language \r\nAnalysis,” Communications of the ACM 13:10, 1970.\r\n","uuid":"925bdc1b-27c2-4a1c-9b5e-39477a2eef52"},"_type":"pdf"},{"_id":"HpFSu4IBzLTTH-8HZylK","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":38,"pages":518,"text":"The History of AI 19\r\nEXERCISES\r\n1. In your own words, define intelligence and why intelligence tests can \r\nhide the real measure of intelligence.\r\n2. What was the Turing test, and what was it intended to accomplish?\r\n3. Why were games the early test-bed for AI methods? How do you think \r\nAI and games are viewed today?\r\n4. How did Arthur Samuel set the bar for learning programs in the 1950s?\r\n5. What was the first language developed specifically for AI? What language \r\nfollowed in the 1970s, developed also for AI?\r\n6. Define Strong AI.\r\n7. What event is most commonly attributed to leading to AI’s winter?\r\n8. What is meant by Scruffy and Neat approaches to AI?\r\n9. After AI’s winter, what was most unique about AI’s re-emergence?\r\n10. This book explores AI from the systems approach. Define the systems \r\napproach and how this perspective is used to explore AI.\r\n","uuid":"5da24f6a-6015-400b-9b44-bd6c61453a9c"},"_type":"pdf"},{"_id":"H5FSu4IBzLTTH-8HZylN","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":39,"pages":518,"text":"\r\n","uuid":"da0940fb-6b17-4474-be02-d62135634554"},"_type":"pdf"},{"_id":"IJFSu4IBzLTTH-8HZylP","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":40,"pages":518,"text":"C h a p t e r\r\nUNINFORMED \r\nSEARCH2\r\nUninformed search, also called blind search and naïve search, is a \r\nclass of general purpose search algorithms that operate in a brute-\r\nforce way. These algorithms can be applied to a variety of search \r\nproblems, but since they don’t take into account the target problem, are \r\ninefficient. In contrast, informed search methods (discussed in Chapter 3) \r\nuse a heuristic to guide the search for the problem at hand and are therefore \r\nmuch more efficient. In this chapter, general state space search is explored \r\nand then a variety of uninformed search algorithms will be discussed and \r\ncompared using a set of common metrics.\r\nSEARCH AND AI\r\nSearch is an important aspect of AI because in many ways, problem solving \r\nin AI is fundamentally a search. Search can be defined as a problem-solving \r\ntechnique that enumerates a problem space from an initial position in search \r\nof a goal position (or solution). The manner in which the problem space is \r\nsearched is defined by the search algorithm or strategy. As search strategies \r\noffer different ways to enumerate the search space, how well a strategy works \r\nis based on the problem at hand. Ideally, the search algorithm selected is one \r\nwhose characteristics match that of the problem at hand.\r\n","uuid":"24b2a9e1-cf11-47c5-a842-fbfad426a197"},"_type":"pdf"},{"_id":"IZFSu4IBzLTTH-8HZylS","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":41,"pages":518,"text":"22 Artificial Intelligence\r\nCLASSES OF SEARCH\r\nFour classes of search will be explored here. In this chapter, we’ll review \r\nuninformed search, and in Chapter 3, informed search will be discussed. \r\nChapter 3 will also review constraint satisfaction, which tries to find a set of \r\nvalues for a set of variables. Finally, in Chapter 4, we’ll discuss adversarial \r\nsearch, which is used in games to find effective strategies to play and win \r\ntwo-player games.\r\nGENERAL STATE SPACE SEARCH\r\nLet’s begin our discussion of search by first understanding what is meant \r\nby a search space. When solving a problem, it’s convenient to think about \r\nthe solution space in terms of a number of actions that we can take, and the \r\nnew state of the environment as we perform those actions. As we take one \r\nof multiple possible actions (each have their own cost), our environment \r\nchanges and opens up alternatives for new actions. As is the case with \r\nmany kinds of problem solving, some paths lead to dead-ends where others \r\nlead to solutions. And there may also be multiple solutions, some better \r\nthan others. The problem of search is to find a sequence of operators that \r\ntransition from the start to goal state. That sequence of operators is the \r\nsolution.\r\nHow we avoid dead-ends and then select the best solution available \r\nis a product of our particular search strategy. Let’s now look at state space \r\nrepresentations for three problem domains.\r\nSearch in a Physical Space\r\nLet’s consider a simple search problem in physical space (Figure 2.1). Our \r\ninitial position is ‘A’ from which there are three possible actions that lead to \r\nposition ‘B,’ ‘C,’ or ‘D.’ Places, or states, are marked by letters. At each place, \r\nthere’s an opportunity for a decision, or action. The action (also called an \r\noperator) is simply a legal move between one place and another. Implied in \r\nthis exercise is a goal state, or a physical location that we’re seeking.\r\nThis search space (shown in Figure 2.1) can be reduced to a tree \r\nstructure as illustrated in Figure 2.2. The search space has been minimized \r\nhere to the necessary places on the physical map (states) and the transitions \r\nthat are possible between the states (application of operators). Each node in \r\nthe tree is a physical location and the arcs between nodes are the legal moves. \r\nThe depth of the tree is the distance from the initial position. \r\n","uuid":"4523040b-9156-4ffe-8c05-e67195522670"},"_type":"pdf"},{"_id":"IpFSu4IBzLTTH-8HZylU","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":42,"pages":518,"text":"Uninformed Search 23\r\nSearch in a Puzzle Space\r\nThe “Towers of Hanoi” puzzle is an interesting example of a state space for \r\nsolving a puzzle problem. The object of this puzzle is to move a number of \r\ndisks from one peg to another (one at a time), with a number of constraints \r\nthat must be met. Each disk is of a unique size and it’s not legal for a larger \r\ndisk to sit on top of a smaller disk. The initial state of the puzzle is such that \r\nall disks begin on one peg in increasing size order (see Figure 2.2). Our goal \r\n(the solution) is to move all disks to the last peg.\r\nAs in many state spaces, there are potential transitions that are not legal. \r\nFor example, we can only move a peg that has no object above it. Further, \r\nwe can’t move a large disk onto a smaller disk (though we can move any disk \r\nFIGURE 2.1: A search problem represented as a physical space.\r\nFIGURE 2.2: Representing the physical space problem in Figure 2.1 as a tree.\r\n","uuid":"4864a75c-2f50-476b-80be-5f4d2564ac7d"},"_type":"pdf"},{"_id":"I5FSu4IBzLTTH-8HZylX","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":43,"pages":518,"text":"24 Artificial Intelligence\r\nto an empty peg). The space of possible operators is therefore constrained \r\nonly to legal moves. The state space can also be constrained to moves that \r\nhave not yet been performed for a given subtree. For example, if we move a \r\nsmall disk from Peg A to Peg C, moving the same disk back to Peg A could \r\nbe defined as an invalid transition. Not doing so would result in loops and \r\nan infinitely deep tree.\r\nConsider our initial position from Figure 2.3. The only disk that may \r\nmove is the small disk at the top of Peg A. For this disk, only two legal moves \r\nare possible, from Peg A to Peg B or C. From this state, there are three \r\npotential moves:\r\n1. Move the small disk from Peg C to Peg B.\r\n2. Move the small disk from Peg C to Peg A.\r\n3. Move the medium disk from Peg A to Peg B.\r\nThe first move (small disk from Peg C to Peg B), while valid is not a potential \r\nmove, as we just moved this disk to Peg C (an empty peg). Moving it a second \r\ntime serves no purpose (as this move could have been done during the prior \r\ntransition), so there’s no value in doing this now (a heuristic). The second \r\nmove is also not useful (another heuristic), because it’s the reverse of the \r\nFIGURE 2.3: A search space for the “Tower of Hanoi” puzzle.\r\n","uuid":"acf693f0-e965-49f1-9e67-791dab6da4bf"},"_type":"pdf"},{"_id":"JJFSu4IBzLTTH-8HZylZ","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":44,"pages":518,"text":"Uninformed Search 25\r\nprevious move. This leaves one valid move, the medium disk from Peg A to \r\nPeg B. The possible moves from this state become more complicated, because \r\nvalid moves are possible that move us farther away from the solution.\r\nTIP  A heuristic is a simple or efficient rule for solving a given problem or \r\nmaking a decision.\r\nWhen our sequence of moves brings us from the initial position to the goal, \r\nwe have a solution. The goal state in itself is not interesting, but instead \r\nwhat’s interesting is the sequence of moves that brought us to the goal state. \r\nThe collection of moves (or solution), done in the proper order, is in essence \r\na plan for reaching the goal. The plan for this configuration of the puzzle \r\ncan be identified by starting from the goal position and backtracking to the \r\ninitial position.\r\nSearch in an Adversarial Game Space\r\nAn interesting use of search spaces is in games. Also known as game trees, \r\nthese structures enumerate the possible moves by each player allowing \r\nthe search algorithm to find an effective strategy for playing and winning \r\nthe game.\r\nNOTE  The topic of adversarial search in game trees is explored in Chapter 4.\r\nConsider a game tree for the game of Chess. Each possible move is provided \r\nfor each possible configuration (placement of pieces) of the Chess board. \r\nBut since there are 10120 possible configurations of a Chess board, a game \r\ntree to document the search space would not be feasible. Heuristic search, \r\nwhich must be applied here, will be discussed in Chapter 3.\r\nLet’s now look at a much simpler game that can be more easily \r\nrepresented in a game tree. The game of Nim is a two-player game where \r\neach player takes turns removing objects from one or more piles. The player \r\nrequired to take the last object loses the game. \r\nNim has been studied mathematically and solved in many different \r\nvariations. For this reason, the player who will win can be calculated based \r\nupon the number of objects, piles, and who plays first in an optimally \r\nplayed game.\r\nNOTE  The game of Nim is said to have originated in China, but can be traced \r\nto Germany as the word nimm can be translated as take. A complete \r\nmathematical theory of Nim was created by Charles Bouton in 1901. \r\n[Bouton 1901]\r\n","uuid":"82e3213f-a2a2-4526-ba7e-0473a085b49e"},"_type":"pdf"},{"_id":"JZFSu4IBzLTTH-8HZylc","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":45,"pages":518,"text":"26 Artificial Intelligence\r\nLet’s walk through an example to see how Nim is played. We’ll begin with \r\na single small pile to limit the number of moves that are required. Figure \r\n2.4 illustrates a short game with a pile of six objects. Each player may take \r\none, two, or three objects from the pile. In this example, Player-1 starts \r\nthe game, but ends the game with a loss (is required to take the last object \r\nwhich results in a loss in the misère form of the game). Had Player-1 taken \r\n3 in its second move, Player-2 would have been left with one resulting in a \r\nwin for Player-1.\r\nA game tree makes this information visible, as illustrated in Figure 2.5. \r\nNote in the tree that Player-1 must remove one from the pile to continue \r\nthe game. If Player-1 removes two or three from the pile, Player-2 can win \r\nif playing optimally. The shaded nodes in the tree illustrate losing positions \r\nfor the player that must choose next (and in all cases, the only choice left is \r\nto take the only remaining object).\r\nNote that the depth of the tree determines the length of the game \r\n(number of moves). It’s implied in the tree that the shaded node is the final \r\nmove to be made, and the player that makes this move loses the game. Also \r\nnote the size of the tree. In this example, using six objects, a total of 28 nodes \r\nis required. If we increase our tree to illustrate a pile of seven objects, the \r\ntree increases to 42 nodes. With eight objects, three balloons to 100 nodes. \r\nFortunately, the tree can be optimized by removing duplicate subtrees, \r\nresulting in a much smaller tree.\r\nFIGURE 2.4: A sample game of Nim with a pile of six objects.\r\n","uuid":"4fc16749-3977-43ef-b732-ce5eb49493c2"},"_type":"pdf"},{"_id":"JpFSu4IBzLTTH-8HZylf","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":46,"pages":518,"text":"Uninformed Search 27\r\nTREES, GRAPHS, AND REPRESENTATION\r\nA short tour of trees and graphs and their terminology is in order before \r\nexploring the various uninformed search methods.\r\nA graph is a finite set of vertices (or nodes) that are connected by edges \r\n(or arcs). A loop (or cycle) may exist in a graph, where an arc (or edge) may \r\nlead back to the original node. Graphs may be undirected where arcs do \r\nnot imply a direction, or they may be directed (called a digraph) where a \r\ndirection is implicit in the arc. An arc can also carry a weight, where a cost \r\ncan be associated with a path.\r\nEach of these graphs also demonstrates the property of connectivity. Both \r\ngraphs are connected because every pair of nodes is connected by a path. If \r\nevery node is connected to every node by an arc, the graph is complete. One \r\nspecial connected graph is called a tree, but it must contain no cycles.\r\nBuilding a representation of a graph is simple and one of the most \r\ncommon representations is the adjacency matrix. This structure is simply \r\nFIGURE 2.5: A complete Nim game tree for six objects in one pile.\r\nFIGURE 2.6: An example of an undirected \r\ngraph containing six nodes and eight arcs.\r\nFIGURE 2.7: An example of a directed \r\ngraph containing six edges and nine arcs.\r\n","uuid":"11b04f82-70f2-423b-b6be-f31958b28471"},"_type":"pdf"},{"_id":"J5FSu4IBzLTTH-8HZyli","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":47,"pages":518,"text":"28 Artificial Intelligence\r\nan N by N matrix (where N is the number of nodes in the graph). Each \r\nelement of the matrix defines a connectivity (or adjacency) between the node \r\nreferenced as the row and the node referenced as the column. \r\nRecall the undirected graph in Figure 2.6. This graph contains six nodes and \r\neight arcs. The adjacency matrix for this undirected graph is shown in Figure \r\n2.9. The two dimensions of the graph identify the source (row) and destination \r\nnodes (column) of the graph. From Figure 2.6, we know that node A is adjacent \r\nto nodes B, C, and D. This is noted in the adjacency matrix with a value of one \r\nin each of the B, C, and D columns for row A. Since this is an undirected graph, \r\nwe note symmetry in the adjacency matrix. Node A connects to node B (as \r\nidentified in row A), but also node B connects to node A (as shown in row B).\r\nFor a directed graph (as shown in Figure 2.7), the associated adjacency \r\nmatrix is illustrated in Figure 2.10. Since the graph is directed, no symmetry \r\ncan be found. Instead, the direction of the arcs is noted in the matrix. \r\nFor example, node B connects to node A, but node A has no associated \r\nconnection to node B.\r\nAn interesting property of the adjacency matrix can be found by reviewing \r\nthe rows and columns in isolation. For example, if we review a single row, we \r\ncan identify the nodes to which it connects. For example, row C shows only a \r\nconnection to node F (as indicated by the one in that cell). But if we review \r\nthe column for node C, we find the nodes that have arcs connecting to node \r\nC. In this case, we see nodes A, D, and E (as illustrated graphically in Figure \r\n2.7). We can also find whether a graph is complete. If the entire matrix is \r\nnon-zero, then the graph is complete. It’s also simple to find a disconnected \r\ngraph (a node whose row and column contain zero values). Loops in a graph \r\ncan also be algorithmically discovered by enumerating the matrix (recursively \r\nFIGURE 2.8: A connected graph with no cycles (otherwise known as a tree).\r\n","uuid":"b3eec2b6-17b1-4b32-8769-456f073bee10"},"_type":"pdf"},{"_id":"KJFSu4IBzLTTH-8HZylk","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":48,"pages":518,"text":"Uninformed Search 29\r\nfollowing all paths looking for the initial node).\r\nIn the simple case, the values of the adjacency matrix simply define the \r\nconnectivity of nodes in the graph. In weighted graphs, where arcs may not \r\nall be equal, the value in a cell can identify the weight (cost, or distance). \r\nWe’ll explore examples of this technique in the review of neural network \r\nconstruction (Chapter 11).\r\nAdjacency lists are also a popular structure where each node contains \r\na list of the nodes to which it connects. If the graph is sparse, this \r\nrepresentation can require less space.\r\nUNINFORMED SEARCH\r\nThe uninformed search methods offer a variety of techniques for graph \r\nsearch, each with its own advantages and disadvantages. These methods are \r\nexplored here with discussion of their characteristics and complexities.\r\nBig-O notation will be used to compare the algorithms. This notation \r\ndefines the asymptotic upper bound of the algorithm given the depth (d) of \r\nthe tree and the branching factor, or the average number of branches (b) \r\nfrom each node. There are a number of common complexities that exist for \r\nsearch algorithms. These are shown in Table 2.1.\r\nTable 2.1: Common orders of search functions.\r\nO-Notation Order\r\nO(1) Constant (regardless of the number of nodes)\r\nFIGURE 2.9: Adjacency matrix for the \r\nundirected graph shown in Figure 2.6.\r\nFIGURE 2.10: Adjacency matrix for the \r\ndirected graph (digraph) shown in Figure 2.7.\r\n","uuid":"7aa75943-6784-44ef-83bb-7cfc291e3b63"},"_type":"pdf"},{"_id":"KZFSu4IBzLTTH-8HZyln","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":49,"pages":518,"text":"30 Artificial Intelligence\r\nO(n) Linear (consistent with the number of nodes)\r\nO(log n) Logarithmic\r\nO(n2) Quadratic\r\nO(cn) Geometric\r\nO(n!) Combinatorial\r\nBig-O notation provides a worst-case measure of the complexity of a search \r\nalgorithm and is a common comparison tool for algorithms. We’ll compare \r\nthe search algorithms using space complexity (measure of the memory \r\nrequired during the search) and time complexity (worst-case time required \r\nto find a solution). We’ll also review the algorithm for completeness (can the \r\nalgorithm find a path to a goal node if it’s present in the graph) and optimality \r\n(finds the lowest cost solution available).\r\nHelper APIs\r\nA number of helper APIs will be used in the source code used to demonstrate \r\nthe search functions. These are shown below in Listing 2.1.\r\nLISTING 2.1: Helper APIs for the search functions.\r\n/* Graph API */\r\ngraph_t *createGraph (int nodes );\r\nvoid destroyGraph (graph_t *g_p );\r\nvoid addEdge (graph_t *g_p, int from, int to, int value );\r\nint getEdge (graph_t *g_p, int from, int to );\r\n/* Stack API */\r\nstack_t  *createStack (int depth );\r\nvoid destroyStack (stack_t *s_p );\r\nvoid pushStack (stack_t *s_p, int value );\r\nint popStack (stack_t *s_p );\r\nint isEmptyStack (stack_t *s_p );\r\n/* Queue API */\r\nqueue_t  *createQueue (int depth );\r\nvoid destroyQueue (queue_t *q_p );\r\nvoid enQueue (queue_t *q_p, int value );\r\nint deQueue (queue_t *q_p );\r\nint isEmptyQueue (queue_t *q_p );\r\n/* Priority Queue API */\r\npqueue_t *createPQueue (int depth );\r\n","uuid":"2164ed69-a861-4b2e-bcae-3defa0e9ce6d"},"_type":"pdf"},{"_id":"KpFSu4IBzLTTH-8HZylp","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":50,"pages":518,"text":"Uninformed Search 31\r\nvoid destroyPQueue (pqueue_t *q_p );\r\nvoid enPQueue (pqueue_t *q_p, int value, int cost );\r\nvoid dePQueue (pqueue_t *q_p, int *value, int *cost );\r\nint isEmptyPQueue (pqueue_t *q_p );\r\nint isFullPQueue (pqueue_t *q_p );\r\nO\r\nN THE CD\r\n The helper functions can be found on the CD-ROM at ./software/\r\ncommon.\r\nGeneral Search Paradigms\r\nBefore we discuss some of the uninformed search methods, let’s look at two \r\nsimple general uninformed search methods. \r\nThe first is called ‘Generate and Test.’ In this method, we generate a \r\npotential solution and then check it against the solution. If we’ve found \r\nthe solution, we’re done, otherwise, we repeat by trying another potential \r\nsolution. This is called ‘Generate and Test’ because we generate a potential \r\nsolution, and then test it. Without a proper solution, we try again. Note here \r\nthat we don’t keep track of what we’ve tried before; we just plow ahead with \r\npotential solutions, which is a true blind search.\r\nAnother option is called ‘Random Search’ which randomly selects a new \r\nstate from the current state (by selecting a given valid operator and applying \r\nit). If we reach the goal state, then we’re done. Otherwise, we randomly \r\nselect another operator (leading to a new state) and continue.\r\nRandom search and the ‘Generate and Test’ method are truly blind \r\nmethods of search. They can get lost, get caught in loops, and potentially \r\nnever find a solution even though one exists within the search space.\r\nLet’s now look at some search methods that while blind, can find a \r\nsolution (if one exists) even if it takes a long period of time.\r\nDepth-First Search (DFS)\r\nThe Depth-First Search (DFS) algorithm is a technique for searching a \r\ngraph that begins at the root node, and exhaustively searches each branch \r\nto its greatest depth before backtracking to previously unexplored branches \r\n(Figure 2.11 illustrates this search order). Nodes found but yet to be \r\nreviewed are stored in a LIFO queue (also known as a stack).\r\nNOTE  A stack is a LIFO (Last-In-First-Out) container of objects. Similar to \r\na stack of paper, the last item placed on the top is the first item to be \r\nremoved.\r\n","uuid":"39ef5196-4f26-46bf-b0c5-66206cf4e0af"},"_type":"pdf"},{"_id":"K5FSu4IBzLTTH-8HZyls","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":51,"pages":518,"text":"32 Artificial Intelligence\r\nThe space complexity for DFS is O(bd) where the time complexity is \r\ngeometric (O(bd)). This can be very problematic on deep branching graphs, \r\nas the algorithm will continue to the maximum depth of the graph. If loops \r\nare present in the graph, then DFS will follow these cycles indefinitely. \r\nFor this reason, the DFS algorithm is not complete, as cycles can prohibit \r\nthe algorithm from finding the goal. If cycles are not present in the graph, \r\nthen the algorithm is complete (will always find the goal node). The DFS \r\nalgorithm is also not optimal, but can be made optimal using path checking \r\n(to ensure the shortest path to the goal is found).\r\nON THE CD\r\n The DFS implementation can be found on the CD-ROM at ./software/\r\nch2/dfs.c.\r\nGraph algorithms can be implemented either recursively or using a stack to \r\nmaintain the list of nodes that must be enumerated. In Listing 2.2, the DFS \r\nalgorithm is implemented using a LIFO stack.\r\nListing 2.2: The depth-first search algorithm.\r\n#include <stdio.h>\r\n#include “graph.h”\r\n#include “stack.h”\r\n#define A 0\r\n#define B 1\r\nFIGURE 2.11: Search order of the DFS algorithm over a small tree.\r\n","uuid":"fdc4f73e-58ad-40e7-ad96-aaccc914511d"},"_type":"pdf"},{"_id":"LJFSu4IBzLTTH-8HZylu","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":52,"pages":518,"text":"Uninformed Search 33\r\n#define C 2\r\n#define D 3\r\n#define E 4\r\n#define F 5\r\n#define G 6\r\n#define H 7\r\nint init_graph( graph_t *g_p )\r\n{\r\n  addEdge( g_p, A, B, 1 );\r\n  addEdge( g_p, A, C, 1 );\r\n  addEdge( g_p, B, D, 1 );\r\n  addEdge( g_p, C, E, 1 );\r\n  addEdge( g_p, C, F, 1 );\r\n  addEdge( g_p, D, G, 1 );\r\n  addEdge( g_p, D, H, 1 );\r\n  return 0;\r\n}\r\nvoid dfs( graph_t *g_p, int root, int goal )\r\n{\r\n  int node;\r\n  int to;\r\n  stack_t *s_p;\r\n  s_p = createStack( 10 );\r\n  pushStack( s_p, root );\r\n  while ( !isEmptyStack(s_p) ) {\r\n    node = popStack( s_p );\r\n    printf(“%d\\n”, node);\r\n    if (node == goal) break;\r\n    for (to = g_p->nodes-1 ; to > 0 ; to--) {\r\n      if (getEdge( g_p, node, to ) ) {\r\n        pushStack( s_p, to );\r\n      }\r\n    }\r\n  }\r\n  destroyStack( s_p );\r\n  return;\r\n}\r\nint main()\r\n{\r\n  graph_t *g_p;\r\n","uuid":"a82f6659-12a1-425b-a10a-51d4acf0809f"},"_type":"pdf"},{"_id":"LZFSu4IBzLTTH-8HZylx","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":53,"pages":518,"text":"34 Artificial Intelligence\r\n  g_p = createGraph( 8 );\r\n  init_graph( g_p );\r\n  dfs( g_p, 0, 5 );\r\n  destroyGraph( g_p );\r\n  return 0;\r\n}\r\nTIP  A search algorithm is characterized as exhaustive when it can search \r\nevery node in the graph in search of the goal. If the goal is not present in \r\nthe graph, the algorithm will terminate, but will search each and every \r\nnode in a systematic way.\r\nDepth-Limited Search (DLS)\r\nDepth-Limited Search (DLS) is a modification of depth-first search that \r\nminimizes the depth that the search algorithm may go. In addition to starting \r\nwith a root and goal node, a depth is provided that the algorithm will not \r\ndescend below (see Listing 2.3). Any nodes below that depth are omitted from \r\nthe search. This modification keeps the algorithm from indefinitely cycling \r\nby halting the search after the pre-imposed depth. Figure 2.12 illustrates this \r\nsearch with a depth of two (no nodes deeper than level two are searched).\r\nON THE CD\r\n The DLS implementation can be found on the CD-ROM at ./software/\r\nch2/dls.c.\r\nListing 2.3: The depth-limited search algorithm.\r\n#include <stdio.h>\r\n#include “graph.h”\r\n#include “stack.h”\r\n#define A 0\r\n#define B 1\r\n#define C 2\r\n#define D 3\r\n#define E 4\r\n#define F 5\r\n#define G 6\r\n#define H 7\r\nint init_graph( graph_t *g_p )\r\n{\r\n","uuid":"e807b45c-9442-4045-9fe8-f394712cf63c"},"_type":"pdf"},{"_id":"LpFSu4IBzLTTH-8HZyl0","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":54,"pages":518,"text":"Uninformed Search 35\r\n  addEdge( g_p, A, B, 1 );\r\n  addEdge( g_p, A, C, 1 );\r\n  addEdge( g_p, B, D, 1 );\r\n  addEdge( g_p, C, E, 1 );\r\n  addEdge( g_p, C, F, 1 );\r\n  addEdge( g_p, D, G, 1 );\r\n  addEdge( g_p, D, H, 1 );\r\n  return 0;\r\n}\r\nvoid dls( graph_t *g_p, int root, int goal, int limit )\r\n{\r\n  int node, depth, to;\r\n  stack_t *s_p, *sd_p;\r\n  s_p = createStack( 10 );\r\n  sd_p = createStack( 10 );\r\n  pushStack( s_p, root );\r\n  pushStack( sd_p, 0 );\r\n  while ( !isEmptyStack(s_p) ) {\r\n    node = popStack( s_p );\r\n    depth = popStack( sd_p );\r\n    printf(“%d (depth %d)\\n”, node, depth);\r\n    if (node == goal) break;\r\n    if (depth < limit) {\r\n      for (to = g_p->nodes-1 ; to > 0 ; to--) {\r\n        if (getEdge( g_p, node, to ) ) {\r\n          pushStack( s_p, to );\r\n          pushStack( sd_p, depth+1 );\r\n        }\r\n      }\r\n    }\r\n  }\r\n  destroyStack( s_p );\r\n  destroyStack( sd_p );\r\n  return;\r\n}\r\nint main()\r\n{\r\n  graph_t *g_p;\r\n  g_p = createGraph( 8 );\r\n  init_graph( g_p );\r\n","uuid":"19a79c95-c6aa-4caf-8c9f-2512e4641f04"},"_type":"pdf"},{"_id":"L5FSu4IBzLTTH-8HZyl2","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":55,"pages":518,"text":"36 Artificial Intelligence\r\n  dls( g_p, 0, 5, 2 );\r\n  destroyGraph( g_p );\r\n  return 0;\r\n}\r\nWhile the algorithm does remove the possibility of infinitely looping in the \r\ngraph, it also reduces the scope of the search. If the goal node had been one \r\nof the nodes marked ‘X’, it would not have been found, making the search \r\nalgorithm incomplete. The algorithm can be complete if the search depth is \r\nthat of the tree itself (in this case d is three). The technique is also not optimal \r\nsince the first path may be found to the goal instead of the shortest path.\r\nThe time and space complexity of depth-limited search is similar to DFS, \r\nfrom which this algorithm is derived. Space complexity is O(bd) and time \r\ncomplexity is O(bd), but d in this case is the imposed depth of the search and \r\nnot the maximum depth of the graph.\r\nIterative Deepening Search (IDS)\r\nIterative Deepening Search (IDS) is a derivative of DLS and combines the \r\nfeatures of depth-first search with that of breadth-first search. IDS operates \r\nby performing DLS searches with increased depths until the goal is found. \r\nFIGURE 2.13: Iterating increased depth searches with IDS.\r\nFIGURE 2.12: Search order for a tree using depth-limited search (depth = two).\r\n","uuid":"8931f371-83a1-4f47-8331-55fcea30dec0"},"_type":"pdf"},{"_id":"MJFSu4IBzLTTH-8HZyl5","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":56,"pages":518,"text":"Uninformed Search 37\r\nThe depth begins at one, and increases until the goal is found, or no further \r\nnodes can be enumerated (see Figure 2.13).\r\nAs shown in Figure 2.13, IDS combines depth-first search with breadth-\r\nfirst search. By minimizing the depth of the search, we force the algorithm to \r\nalso search the breadth of the graph. If the goal is not found, the depth that \r\nthe algorithm is permitted to search is increased and the algorithm is started \r\nagain. The algorithm, shown in Listing 2.4, begins with a depth of one.\r\nLISTING 2.4: The iterative deepening-search algorithm.\r\n#include <stdio.h>\r\n#include “graph.h”\r\n#include “stack.h”\r\n#define A 0\r\n#define B 1\r\n#define C 2\r\n#define D 3\r\n#define E 4\r\n#define F 5\r\n#define G 6\r\n#define H 7\r\nint init_graph( graph_t *g_p )\r\n{\r\n  addEdge( g_p, A, B, 1 );\r\n  addEdge( g_p, A, C, 1 );\r\n  addEdge( g_p, B, D, 1 );\r\n  addEdge( g_p, C, E, 1 );\r\n  addEdge( g_p, C, F, 1 );\r\n  addEdge( g_p, D, G, 1 );\r\n  addEdge( g_p, D, H, 1 );\r\n  return 0;\r\n}\r\nint dls( graph_t *g_p, int root, int goal, int limit )\r\n{\r\n  int node, depth;\r\n  int to;\r\n  stack_t *s_p, *sd_p;\r\n  s_p = createStack( 10 );\r\n  sd_p = createStack( 10 );\r\n  pushStack( s_p, root );\r\n","uuid":"941c0ead-4bf5-48bd-97f4-c72f8e380ba7"},"_type":"pdf"},{"_id":"MZFSu4IBzLTTH-8HZyl8","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":57,"pages":518,"text":"38 Artificial Intelligence\r\n  pushStack( sd_p, 0 );\r\n  while ( !isEmptyStack(s_p) ) {\r\n    node = popStack( s_p );\r\n    depth = popStack( sd_p );\r\n    printf(“%d (depth %d)\\n”, node, depth);\r\n    if (node == goal) return 1;\r\n    if (depth < limit) {\r\n      for (to = g_p->nodes-1 ; to > 0 ; to--) {\r\n        if (getEdge( g_p, node, to ) ) {\r\n          pushStack( s_p, to );\r\n          pushStack( sd_p, depth+1 );\r\n        }\r\n      }\r\n    }\r\n  }\r\n  destroyStack( s_p );\r\n  destroyStack( sd_p );\r\n  return 0;\r\n}\r\nint main()\r\n{\r\n  graph_t *g_p;\r\n  int     status, depth;\r\n  g_p = createGraph( 8 );\r\n  init_graph( g_p );\r\n  depth = 1;\r\n  while (1) {\r\n    status = dls( g_p, 0, 5, depth );\r\n    if (status == 1) break;\r\n    else depth++;\r\n  }\r\n  destroyGraph( g_p );\r\n  return 0;\r\n}\r\nON THE CD\r\n The IDS implementation can be found on the CD-ROM at ./software/\r\nch2/ids.c.\r\nIDS is advantageous because it’s not susceptible to cycles (a characteristic \r\nof DLS, upon which it’s based). It also finds the goal nearest to the root node, \r\n","uuid":"54fc3cb2-ddd1-491a-96a8-ea3ab08cc45b"},"_type":"pdf"},{"_id":"MpFSu4IBzLTTH-8HZyl-","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":58,"pages":518,"text":"Uninformed Search 39\r\nas does the BFS algorithm (which will be detailed next). For this reason, it’s \r\na preferred algorithm when the depth of the solution is not known.\r\nThe time complexity for IDS is identical to that of DFS and DLS, O(bd). \r\nSpace complexity of IDS is O(bd).\r\nUnlike DFS and DLS, IDS is will always find the best solution and \r\ntherefore, it is both complete and optimal.\r\nBreadth-First Search (BFS)\r\nIn Breadth-First Search (BFS), we search the graph from the root node in \r\norder of the distance from the root. Because the order search is nearest the \r\nroot, BFS is guaranteed to find the best possible solution (shallowest) in a \r\nnon-weighted graph, and is therefore also complete. Rather than digging \r\ndeep down into the graph, progressing further and further from the root \r\n(as is the case with DFS), BFS checks each node nearest the root before \r\ndescending to the next level (see Figure 2.14).\r\nThe implementation of BFS uses a FIFO (first-in-first-out) queue, \r\ndiffering from the stack (LIFO) implementation for DFS. As new nodes \r\nare found to be searched, these nodes are checked against the goal, and if \r\nthe goal is not found, the new nodes are added to the queue. To continue \r\nthe search, the oldest node is dequeued (FIFO order). Using FIFO order \r\nfor new node search, we always check the oldest nodes first, resulting in \r\nbreadth-first review (see Listing 2.5).\r\nLISTING 2.5: The breadth-first search algorithm.\r\n#include <stdio.h>\r\n#include “graph.h”\r\n#include “queue.h”\r\n#define A 0\r\nFIGURE 2.14: Search order of the breadth-first search algorithm.\r\n","uuid":"2cfa3c06-a8ca-4348-9436-d47eeb7e6ac9"},"_type":"pdf"},{"_id":"M5FSu4IBzLTTH-8HZymB","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":59,"pages":518,"text":"40 Artificial Intelligence\r\n#define B 1\r\n#define C 2\r\n#define D 3\r\n#define E 4\r\n#define F 5\r\n#define G 6\r\n#define H 7\r\nint init_graph( graph_t *g_p )\r\n{\r\n  addEdge( g_p, A, B, 1 );\r\n  addEdge( g_p, A, C, 1 );\r\n  addEdge( g_p, B, D, 1 );\r\n  addEdge( g_p, C, E, 1 );\r\n  addEdge( g_p, C, F, 1 );\r\n  addEdge( g_p, D, G, 1 );\r\n  addEdge( g_p, D, H, 1 );\r\n  return 0;\r\n}\r\nvoid bfs( graph_t *g_p, int root, int goal )\r\n{\r\n  int node;\r\n  int to;\r\n  queue_t *q_p;\r\n  q_p = createQueue( 10 );\r\n  enQueue( q_p, root );\r\n  while ( !isEmptyQueue(q_p) ) {\r\n    node = deQueue( q_p );\r\n    printf(“%d\\n”, node);\r\n    if (node == goal) break;\r\n    for (to = g_p->nodes-1 ; to > 0 ; to--) {\r\n      if (getEdge( g_p, node, to ) ) {\r\n        enQueue( q_p, to );\r\n      }\r\n    }\r\n  }\r\n  destroyQueue( q_p );\r\n  return;\r\n}\r\nint main()\r\n{\r\n","uuid":"77deb79c-bc2e-4b27-86ae-63c2c3965994"},"_type":"pdf"},{"_id":"NJFSu4IBzLTTH-8HZymD","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":60,"pages":518,"text":"Uninformed Search 41\r\n  graph_t *g_p;\r\n  g_p = createGraph( 8 );\r\n  init_graph( g_p );\r\n  bfs( g_p, 0, 7 );\r\n  destroyGraph( g_p );\r\n  return 0;\r\n}\r\nON THE CD\r\n The BFS implementation can be found on the CD-ROM at ./software/\r\nch2/bfs.c.\r\nThe disadvantage of BFS is that each node that is searched is required \r\nto be stored (space complexity is O(bd)). The entire depth of the tree does \r\nnot have to be searched, so d in this context is the depth of the solution, and \r\nnot the maximum depth of the tree. Time complexity is also O(bd).\r\nTIP  In practical implementations of BFS, and other search algorithms, a \r\nclosed list is maintained that contains those nodes in the graph that \r\nhave been visited. This allows the algorithm to efficiently search the \r\ngraph without re-visiting nodes. In implementations where the graph is \r\nweighted, keeping a closed list is not possible.\r\nFIGURE 2.15: Bidirectional search meeting in the middle at node H.\r\n","uuid":"ffcad38c-1882-4fbf-9100-4497fe16eb16"},"_type":"pdf"},{"_id":"NZFSu4IBzLTTH-8HZymF","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":61,"pages":518,"text":"42 Artificial Intelligence\r\nBidirectional Search\r\nThe Bidirectional Search algorithm is a derivative of BFS that operates by \r\nperforming two breadth-first searches simultaneously, one beginning from \r\nthe root node and the other from the goal node. When the two searches \r\nmeet in the middle, a path can be reconstructed from the root to the goal. \r\nThe searches meeting is determined when a common node is found (a node \r\nvisited by both searches, see Figure 2.15). This is accomplished by keeping \r\na closed list of the nodes visited.\r\nBidirectional search is an interesting idea, but requires that we know the \r\ngoal that we’re seeking in the graph. This isn’t always practical, which limits \r\nthe application of the algorithm. When it can be determined, the algorithm \r\nhas useful characteristics. The time and space complexity for bidirectional \r\nsearch is O(bd/2), since we’re only required to search half of the depth of \r\nthe tree. Since it is based on BFS, bidirectional search is both complete and \r\noptimal.\r\nUniform-Cost Search (UCS)\r\nOne advantage of BFS is that it always finds the shallowest solution. But \r\nconsider the edge having a cost associated with it. The shallowest solution \r\nmay not be the best, and a deeper solution with a reduced path cost would \r\nbe better (for example, see Figure 2.16). Uniform -Cost Search (UCS) can \r\nbe applied to find the least-cost path through a graph by maintaining an \r\nordered list of nodes in order of descending cost. This allows us to evaluate \r\nthe least cost path first \r\nFIGURE 2.16: An example graph where choosing the lowest cost path for the first node (A->C) \r\nmay not result in the best overall path through the graph (A->B->E).\r\n","uuid":"326f9f2e-22b2-4121-9385-bb38750631aa"},"_type":"pdf"},{"_id":"NpFSu4IBzLTTH-8HZymI","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":62,"pages":518,"text":"Uninformed Search 43\r\nTIP  Uniform-cost search is an uninformed search method because no heuristic \r\nis actually used. The algorithm measures the actual cost of the path \r\nwithout attempting to estimate it.\r\nThe algorithm for UCS uses the accumulated path cost and a priority queue \r\nto determine the path to evaluate (see Listing 2.6). The priority queue \r\n(sorted from least cost to greatest) contains the nodes to be evaluated. As \r\nnode children are evaluated, we add their cost to the node with the aggregate \r\nsum of the current path. This node is then added to the queue, and when \r\nall children have been evaluated, the queue is sorted in order of ascending \r\ncost. When the first element in the priority queue is the goal node, then the \r\nbest solution has been found.\r\nLISTING 2.6: The uniform-cost search algorithm.\r\n#include <stdio.h>\r\n#include “graph.h”\r\n#include “pqueue.h”\r\n#define A 0\r\n#define B 1\r\n#define C 2\r\n#define D 3\r\n#define E 4\r\nint init_graph( graph_t *g_p )\r\n{\r\n  addEdge( g_p, A, B, 5 );\r\n  addEdge( g_p, A, C, 1 );\r\n  addEdge( g_p, A, D, 2 );\r\n  addEdge( g_p, B, E, 1 );\r\n  addEdge( g_p, C, E, 7 );\r\n  addEdge( g_p, D, E, 5 );\r\n  return 0;\r\n}\r\nvoid ucs( graph_t *g_p, int root, int goal )\r\n{\r\n  int node, cost, child_cost;\r\n  int to;\r\n  pqueue_t *q_p;\r\n  q_p = createPQueue( 7 );\r\n  enPQueue( q_p, root, 0 );\r\n  while ( !isEmptyPQueue(q_p) ) {\r\n","uuid":"f8c991c6-8944-4690-a90e-32abcf7cdb5e"},"_type":"pdf"},{"_id":"N5FSu4IBzLTTH-8HZymL","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":63,"pages":518,"text":"44 Artificial Intelligence\r\n    dePQueue( q_p, &node, &cost );\r\n    if (node == goal) {\r\n      printf(“cost %d\\n”, cost);\r\n      return;\r\n    }\r\n    for (to = g_p->nodes-1 ; to > 0 ; to--) {\r\n      child_cost = getEdge( g_p, node, to );\r\n      if (child_cost) {\r\n        enPQueue( q_p, to, (child_cost+cost) );\r\n      }\r\n    }\r\n  }\r\n  destroyPQueue( q_p );\r\n  return;\r\n}\r\nint main()\r\n{\r\n  graph_t *g_p;\r\n  g_p = createGraph( 6 );\r\n  init_graph( g_p );\r\n  ucs( g_p, A, E );\r\n  destroyGraph( g_p );\r\n  return 0;\r\n}\r\nFIGURE 2.17: Node evaluations and the \r\nstate of the priority queue.\r\nFIGURE 2.18: Illustrating the path cost \r\nthrough the graph.\r\n","uuid":"0b321c2c-6de5-4220-993e-19624ea58b8c"},"_type":"pdf"},{"_id":"OJFSu4IBzLTTH-8HZymN","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":64,"pages":518,"text":"Uninformed Search 45\r\nO\r\nN THE CD\r\n The UCS implementation can be found on the CD-ROM at ./software/\r\nch2/ucs.c.\r\nThe UCS algorithm is easily demonstrated using our example graph in \r\nFigure 2.16. Figure 2.17 shows the state of the priority queue as the nodes \r\nare evaluated. At step one, the initial node has been added to the priority \r\nqueue, with a cost of zero. At step two, each of the three connected nodes \r\nare evaluated and added to the priority queue. When no further children are \r\navailable to evaluate, the priority queue is sorted to place them in ascending \r\ncost order.\r\nAt step three, children of node C are evaluated. In this case, we find the \r\ndesired goal (E), but since its accumulated path cost is eight, it ends up at \r\nthe end of the queue. For step four, we evaluate node D and again find the \r\ngoal node. The path cost results in seven, which is still greater than our B \r\nnode in the queue. Finally, at step five, node B is evaluated. The goal node is \r\nfound again, with a resulting path cost of six. The priority queue now contains \r\nthe goal node at the top, which means at the next iteration of the loop, the \r\nalgorithm will exit with a path of A->B->E (working backwards from the \r\ngoal node to the initial node).\r\nTo limit the size of the priority queue, it’s possible to prune entries that are \r\nredundant. For example, at step 4 in Figure 2.17, the entry for E(8) could have \r\nbeen safely removed, as another path exists that has a reduced cost (E(7)).\r\nThe search of the graph is shown in Figure 2.18, which identifies the path \r\ncost at each edge of the graph. The path cost shown above the goal node (E) \r\nmakes it easy to see the least-cost path through the graph, even when it’s not \r\napparent from the initial node.\r\nUCS is optimal and can be complete, but only if the edge costs are \r\nnon-negative (the summed path cost always increases). Time and space \r\ncomplexity are the same as BFS, O(bd) for each, as it’s possible for the entire \r\ntree to be evaluated.\r\nIMPROVEMENTS\r\nOne of the basic problems with traditional DFS and BFS is that they \r\nlack a visited list (a list of nodes that have already been evaluated). This \r\nmodification makes the algorithms complete, by ignoring cycles and only \r\nfollowing paths that have not yet been followed. For BFS, keeping a visited \r\nlist can reduce the search time, but for DFS, the algorithm can be made \r\ncomplete.\r\n","uuid":"3f449ae7-b6f2-4062-b0c3-6451d015d885"},"_type":"pdf"},{"_id":"OZFSu4IBzLTTH-8HZymQ","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":65,"pages":518,"text":"46 Artificial Intelligence\r\nALGORITHM ADVANTAGES\r\nEach of the algorithms has advantages and disadvantages based on the graph \r\nto be searched. For example, if the branching factor of the graph is small, \r\nthen BFS is the best choice. If the tree is deep, but a solution is known to \r\nbe shallow in the graph, then IDS is a good choice. If the graph is weighted, \r\nthen UCS should be used as it will always find the best solution where DFS \r\nand BFS will not.\r\nCHAPTER SUMMARY\r\nUninformed search algorithms are a class of graph search algorithms that \r\nexhaustively search for a node without the use of a heuristic to guide the \r\nsearch. Search algorithms are of interest in AI because many problems can \r\nbe reduced to simple search problems in a state space. The state space \r\nconsists of states (nodes) and operators (edges), allowing the state space to \r\nbe represented as a graph. Examples range from graphs of physical spaces \r\nto massive game trees such as are possible with the game of Chess.\r\nThe depth-first search algorithm operates by evaluating branches to \r\ntheir maximum depth, and then backtracking to follow unvisited branches. \r\nDepth-limited search (DLS) is based on DFS, but restricts the depth of the \r\nsearch. Iterative-deepening search (IDS) uses DLS, but continually increases \r\nthe search depth until the solution is found.\r\nThe breadth-first search (BFS) algorithm searches with increasing \r\ndepth from the root (searches all nodes with depth one, then all nodes with \r\ndepth two, etc.). A special derivative algorithm of BFS, bidirectional search \r\n(BIDI), performs two simultaneous searches. Starting at the root node and \r\nthe goal node, BIDI performs two BFS searches in search of the middle. \r\nOnce a common node is found in the middle, a path exists between the root \r\nand goal nodes.\r\nThe uniform-cost search (UCS) algorithm is ideal for weight graphs \r\n(graphs whose edges have costs associated with them). UCS evaluates a graph \r\nusing a priority queue that is ordered in path cost to the particular node.  It’s \r\nbased on the BFS algorithm and is both complete and optimal.\r\nALGORITHMS SUMMARY\r\nTable 2.2:  Summary of the uninformed algorithms and their \r\ncharacteristics.\r\n","uuid":"92f6543b-7af2-4d67-921d-577e9b6bb425"},"_type":"pdf"},{"_id":"OpFSu4IBzLTTH-8HZymT","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":66,"pages":518,"text":"Uninformed Search 47\r\nAlgorithm Time Space Optimal Complete Derivative\r\nDFS O(bm) O(bm) No No\r\nDLS O(bl) O(bl) No No DFS\r\nIDS O(bd) O(bd) Yes No DLS\r\nBFS O(bd) O(bd) Yes Yes\r\nBIDI O(bd/2) O(bd/2) Yes Yes BFS\r\nUCS O(bd) O(bd) Yes Yes BFS\r\nb, branching factor\r\nd, tree depth of the solution\r\nm, tree depth\r\nl, search depth limit\r\nREFERENCES\r\n[Bouton 1901] “Nim, a game with a complete mathematical theory,” Ann, \r\nMath, Princeton 3, 35-39, 1901-1902.\r\nEXERCISES\r\n1. What is uninformed (or blind) search and how does it differ from \r\ninformed (or heuristic) search?\r\n2. The graph structure is ideal for general state space representation. \r\nExplain why and define the individual components.\r\n3. Define the queuing structures used in DFS and BFS and explain why \r\neach uses their particular style.\r\n4. What is the definition of tree depth?\r\n5. What is the definition of the branching factor?\r\n6. What are time and space complexity and why are they useful as metrics \r\nfor graph search?\r\n7. If an algorithm always finds a solution in a graph, what is this property \r\ncalled? If it always finds the best solution, what is this characteristic?\r\n8. Considering DFS and BFS, which algorithm will always find the best \r\nsolution for a non-weighted graph?\r\n9. Use the DFS and BFS algorithms to solve the Towers of Hanoi problem. \r\nWhich performs better and why?\r\n10. Provide the search order for the nodes shown in Figure 2.19 for DFS, BFS, \r\nDLS (d=2), IDS (start depth = 1), and BIDI (start node A, goal node I).\r\n","uuid":"6db09b96-5ed5-47b2-b8b4-e895a1aa34fe"},"_type":"pdf"},{"_id":"O5FSu4IBzLTTH-8HZymV","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":67,"pages":518,"text":"48 Artificial Intelligence\r\n11. In general, IDS is better than DFS. Draw a graph where this is not the \r\ncase.\r\n12. In general, IDS is not complete. Why?\r\n13. Identify a major disadvantage of bidirectional search.\r\n14. Using the UCS algorithm, find the shortest path from A to F in Figure 2.20. \r\nFIGURE 2.19: Example graph. FIGURE 2.20: Example \r\nweighted graph.\r\n","uuid":"3915e088-d21a-49a5-8e11-95e55215a43b"},"_type":"pdf"},{"_id":"PJFSu4IBzLTTH-8HZymY","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":68,"pages":518,"text":"C h a p t e r 3 INFORMED SEARCH\r\nIn Chapter 2, we explored the uninformed search methods such as \r\ndepth-first and breadth-first search. These methods operate in a brute-\r\nforce fashion and are subsequently inefficient. In contrast, this chapter \r\nwill present the informed search methods. These methods incorporate a \r\nheuristic, which is used to determine the quality of any state in the search \r\nspace. In a graph search, this results in a strategy for node expansion (which \r\nnode should be evaluated next). A variety of informed search methods will be \r\ninvestigated and, as with uninformed methods, compared using a common \r\nset of metrics.\r\nNOTE  A heuristic is a rule of thumb that may help solve a given problem. \r\nHeuristics take problem knowledge into consideration to help guide the \r\nsearch within the domain.\r\nINFORMED SEARCH\r\nIn this chapter, we’ll explore a number of informed search methods, including \r\nbest-first search, a-star search, iterative improvement algorithms such as hill \r\nclimbing and simulated annealing, and finally, constraint satisfaction. We’ll \r\ndemonstrate each with a sample problem and illustrate the heuristics used.\r\n","uuid":"69f715e4-3260-4784-9615-14ba31b4ecd2"},"_type":"pdf"},{"_id":"PZFSu4IBzLTTH-8HZymb","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":69,"pages":518,"text":"50 Artificial Intelligence\r\nBEST-FIRST SEARCH (BEST-FS)\r\nIn Best-First search, the search space is evaluated according to a heuristic \r\nfunction. Nodes yet to be evaluated are kept on an OPEN list and those that \r\nhave already been evaluated are stored on a CLOSED list. The OPEN list is \r\nrepresented as a priority queue, such that unvisited nodes can be dequeued \r\nin order of their evaluation function (recall the priority queue from Chapter \r\n2 for the Uniform-Cost Search).\r\nThe evaluation function f(n) is made up of two parts. These are the \r\nheuristic function (h(n)) and the estimated cost (g(n)), where (see Eq 3.1):\r\nf (n) = g(n)+h(n)    (Eq 3.1)\r\nWe can think of the estimated cost as a value measurable from our search \r\nspace, and the heuristic function as an educated guess. The OPEN list is \r\nthen built in order of f(n). This makes best-first search fundamentally greedy \r\nbecause it always chooses the best local opportunity in the search frontier.\r\nNOTE  The search frontier is defined as the set of node opportunities that can be \r\nsearched next. In Best-First search, the frontier is a priority queue sorted \r\nin f(n) order. Given the strict order of f(n), the selection of the node to \r\nevaluate from the priority queue is greedy.\r\nThe complexity of best-first is O(bm) for both time and space (all nodes \r\nare saved in memory). By maintaining a CLOSED list (to avoid revisiting \r\nnodes and therefore avoiding loops) best-first search is complete, but it is \r\nnot optimal, as a solution can be found in a longer path (higher h(n) with a \r\nlower g(n) value.\r\nTIP  Best-First search is a combination of evaluation functions, h(n) and g(n). \r\nNote that Breadth-First search is a special case of Best-First search where \r\nf(n) = h(n), and Uniform-Cost search is a special case of Best-First search \r\nwhere f(n) = g(n).\r\nBest-First Search and the N-Queens Problem\r\nLet’s now discuss the best-first search algorithm in the context of a large \r\nsearch space. The N-queens problem is a search problem where the desired \r\nresult is an N by N board with N queens such that no queen threatens \r\nanother (see Figure 3.1). For this board, in each of the horizontal, vertical, \r\nand diagonal rows, no queen is able to capture another.\r\n","uuid":"2966e440-3619-40fe-b858-dff1a9282295"},"_type":"pdf"},{"_id":"PpFSu4IBzLTTH-8HZymd","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":70,"pages":518,"text":"Informed Search 51\r\nAn important aspect of problem solving and search is representation. For \r\nthis example, we’ll choose a simple representation that fits the solution space \r\nwell and makes it simple to enumerate. Each board position is represented \r\nby a single bit and if the bit is zero, then the position is vacant, otherwise, \r\nit is occupied by a queen. We’ll simplify the problem by assigning a queen \r\nto each row on the board. Enumerating the search space is then defined as \r\nlooking at the possible moves of queens horizontally. For example, the queen \r\nat the top of Figure 3.1 can move left or right, but the queen in the second \r\nrow can only move right (see Figure 3.1). Figure 3.2 also shows the board \r\nrepresentation as a 16-bit value (unsigned short, in the case of C).\r\nGiven a state (the board configuration), we can identify the child states \r\nfor this board by creating a new board for each of the possible queen \r\nFIGURE 3.1: Sample N-Queens board (where N=4).\r\nFIGURE 3.2: Board representation for the N-Queens problem (where N=4).\r\n","uuid":"03686e3d-38ab-4ff0-ba02-cb79549d4ac3"},"_type":"pdf"},{"_id":"P5FSu4IBzLTTH-8HZymg","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":71,"pages":518,"text":"52 Artificial Intelligence\r\nposition changes, given horizontal movement only. For Figure 3.2, this board \r\nconfiguration can result in six new child states (a single queen change position \r\nin each). Note that since we maintain a closed list, board configurations that \r\nhave already been evaluated are not generated, resulting in a small tree and \r\nmore efficient search.\r\nFor the heuristic, we’ll use the node’s depth in the tree for h(n), and \r\nthe number of conflicts (number of queens that could capture another) \r\nfor g(n).\r\nBest-First Search Implementation\r\nLet’s now look at a simple implementation of Best-First search in the C \r\nlanguage. We’ll present the two major functions that make up this search \r\nalgorithm; the first is best_fs, which is the main loop of the algorithm. The \r\nsecond function, generateChildNodes, builds out the possible states (board \r\nconfigurations) given the current state.\r\nOur main function (best_fs) is the OPEN list enumerator and solution \r\ntester. Prior to calling this function, our OPEN list (priority queue) \r\nand CLOSED list have been created. The root node, our initial board \r\nconfiguration, has been placed on the OPEN list. The best_fs function (see \r\nListing 3.1) then dequeues the next node from the open list (best f(n))  If \r\nthis node has a g(n) (number of conflicts) of zero, then a solution has been \r\nfound, and we exit.\r\nLISTING 3.1: The Best-Search first main function.\r\nvoid best_fs ( pqueue_t *open_pq_p, queue_t *closed_q_p )\r\n{\r\n  node_t *node_p;\r\n  int    cost;\r\n  /* Enumerate the Open list */\r\n  while ( !isEmptyPQueue (open_pq_p) ) {\r\n    dePQueue ( open_pq_p, (int *)&node_p, &cost );\r\n    /* Solution found? */\r\n    if (node_p->g == 0) {\r\n      printf(“Found Solution (depth %d):\\n”, node_p->h);\r\n      emitBoard ( node_p );\r\n      break;\r\n    }\r\n    generateChildNodes( open_pq_p, closed_q_p, node_p );\r\n","uuid":"fccfb9e4-5aee-4b16-8ddd-3af575edeb5e"},"_type":"pdf"},{"_id":"QJFSu4IBzLTTH-8HZymi","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":72,"pages":518,"text":"Informed Search 53\r\n  }\r\n  return;\r\n}\r\nNote in Listing 3.1 that while cost is the f(n), we check g(n) to determine \r\nwhether a solution is found.  This is because f(n) may be non-zero since it \r\nincludes the depth of the solution (h(n)).\r\nO\r\nN THE CD\r\n The BestFS implementation can be found on the CD-ROM at ./software/\r\nch3/bestfs.c.\r\nThe next function, generateChildNodes, takes the current board configuration \r\nand enumerates all possible child configurations by potentially moving each \r\nqueen one position.  The moves array defines the possible moves for each \r\nposition on the board (-1 means only right, 2 means both left and right, and \r\n1 means only left). The board is then enumerated, and whenever a queen is \r\nfound, the moves array is checked for the legal moves, and new child nodes \r\nare created and loaded onto the OPEN list. \r\nNote that we check the CLOSED list here to avoid creating a board \r\nconfiguration that we’ve seen before. Once all positions on the current board \r\nhave been checked, and new child nodes are created, the function returns \r\nto best_fs.\r\nWhen a new board configuration is found, the createNode function \r\nis called to allocate a new node structure and places this new node on the \r\nOPEN list (and CLOSED list). Note here that the one plus the depth (h(n)) \r\nis passed in to identify the level of the solution in the tree.\r\nLISTING 3.2: The generateChildNodes function to enumerate the child nodes.\r\nvoid generateChildNodes( pqueue_t *pq_p, \r\n                          queue_t *closed_q_p, node_t *node_p )\r\n{\r\n  int i;\r\n  unsigned short cboard1, cboard2;\r\n  const int moves[16]={ -1, 2, 2, 1, \r\n                        -1, 2, 2, 1, \r\n                        -1, 2, 2, 1, \r\n                        -1, 2, 2, 1 };\r\n/* Generate the child nodes for the current node by \r\n * shuffling the pieces on the board.\r\n","uuid":"1e8b60f5-5824-49d7-a813-0d2aaff69548"},"_type":"pdf"},{"_id":"QZFSu4IBzLTTH-8HZyml","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":73,"pages":518,"text":"54 Artificial Intelligence\r\n   */\r\n  for (i = 0 ; i < 16 ; i++) {\r\n    /* Is there a queen at this position? */\r\n    if (checkPiece( node_p->board, i )) {\r\n      /* Remove current queen from the board */\r\n      cboard1 = cboard2 = ( node_p->board & ~(1 << (15-i) ) );\r\n      if (moves[i] == -1) {\r\n        /* Can only move right */\r\n        cboard1 |= ( 1 << (15-(i+1)) );\r\n        if (!searchQueue( closed_q_p, cboard1)) {\r\n          (void)createNode( pq_p, closed_q_p, cboard1, node_p->h+1 );\r\n        }\r\n      } else if (moves[i] == 2) {\r\n        /* Can move left or right */\r\n        cboard1 |= ( 1 << (15-(i+1)) );\r\n        if (!searchQueue( closed_q_p, cboard1)) {\r\n          (void)createNode( pq_p, closed_q_p, cboard1, node_p->h+1 );\r\n        }\r\n        cboard2 |= ( 1 << (15-(i-1)) );\r\n        if (!searchQueue( closed_q_p, cboard2)) {\r\n          (void)createNode( pq_p, closed_q_p, cboard2, node_p->h+1 );\r\n        }\r\n      } else if (moves[i] == 1) {\r\n        /* Can only move left */\r\n        cboard2 |= ( 1 << (15-(i-1)) );\r\n        if (!searchQueue( closed_q_p, cboard2)) {\r\n          (void)createNode( pq_p, closed_q_p, cboard2, node_p->h+1 );\r\n        }\r\n      }\r\n    }\r\n  }\r\n  return;\r\n}\r\nLet’s now watch the algorithm in action. Once invoked, a random root node \r\nis enqueued and then the possible child configurations are enumerated and \r\nloaded onto the OPEN list (see Listing 3.3). The demonstration here shows \r\na shallow tree of three configurations checked, the root node, one at level \r\none, and the solution found at depth two. A condensed version of this run \r\nis shown in Figure 3.3.\r\n","uuid":"6a2261f0-357b-4f58-8ea3-4c5678f11071"},"_type":"pdf"},{"_id":"QpFSu4IBzLTTH-8HZymn","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":74,"pages":518,"text":"Informed Search 55\r\nLISTING 3.3: Best-First Search for the N-Queens problem (N=4).\r\n    New node: evaluateBoard 4824 = (h 0, g 3)\r\nInitial Board:\r\nboard is 0x4824\r\n0 1 0 0 \r\n1 0 0 0 \r\nFIGURE 3.3: Graphical (condensed) view of the search tree in Listing 3.3.\r\n","uuid":"35b53aca-5b41-408d-be75-4b190c68c9d4"},"_type":"pdf"},{"_id":"Q5FSu4IBzLTTH-8HZymp","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":75,"pages":518,"text":"56 Artificial Intelligence\r\n0 0 1 0 \r\n0 1 0 0 \r\nChecking board 0x4824 (h 0 g 3)\r\n    New node: evaluateBoard 2824 = (h 1, g 2)\r\n    New node: evaluateBoard 8824 = (h 1, g 3)\r\n    New node: evaluateBoard 4424 = (h 1, g 4)\r\n    New node: evaluateBoard 4814 = (h 1, g 3)\r\n    New node: evaluateBoard 4844 = (h 1, g 4)\r\n    New node: evaluateBoard 4822 = (h 1, g 3)\r\n    New node: evaluateBoard 4828 = (h 1, g 2)\r\nChecking board 0x2824 (h 1 g 2)\r\n    New node: evaluateBoard 1824 = (h 2, g 1)\r\n    New node: evaluateBoard 2424 = (h 2, g 5)\r\n    New node: evaluateBoard 2814 = (h 2, g 0)\r\n    New node: evaluateBoard 2844 = (h 2, g 2)\r\n    New node: evaluateBoard 2822 = (h 2, g 3)\r\n    New node: evaluateBoard 2828 = (h 2, g 2)\r\nChecking board 0x2814 (h 2 g 0)\r\nFound Solution (h 2 g 0):\r\nboard is 0x2814\r\n0 0 1 0 \r\n1 0 0 0 \r\n0 0 0 1 \r\n0 1 0 0\r\nVariants of Best-First Search\r\nOne interesting variant of best-first search is called greedy best-first search. \r\nIn this variant, f(n) = h(n), and the OPEN list is ordered in f order. Since \r\nh is the only factor used to determine which node to select next (identified \r\nas the closeness to the goal), it’s defined as greedy. Because of this, greedy \r\nbest-first is not complete as the heuristic is not admissible (because it can \r\noverestimate the path to the goal). We’ll discuss admissibility in more detail \r\nin the discussion of A-star search.\r\nAnother variant of best-first search is beam-search, like greedy best-first \r\nsearch, it uses the heuristic f(n) = h(n). The difference with beam-search is \r\nthat it keeps only a set of the best candidate nodes for expansion and simply \r\nthrows the rest way. This makes beam-search much more memory efficient \r\nthan greedy best-first search, but suffers in that nodes can be discarded \r\nwhich could result in the optimal path. For this reason, beam-search is \r\nneither optimal or complete.\r\n","uuid":"c9fcef79-4482-44af-8a8e-b6376d4c8382"},"_type":"pdf"},{"_id":"RJFSu4IBzLTTH-8HZymt","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":76,"pages":518,"text":"Informed Search 57\r\nA* SEARCH\r\nA* search, like best-first search, evaluates a search space using a heuristic \r\nfunction. But A* uses both the cost of getting from the initial state to the \r\ncurrent state (g(n)), as well as an estimated cost (heuristic) of the path from \r\nthe current node to the goal (h(n)). These are summed to the cost function f(n) \r\n(See Eq 3.1). The A* search, unlike best-first, is both optimal and complete.\r\nThe OPEN and CLOSED lists are used again to identify the frontier for \r\nsearch (OPEN list) and the nodes evaluated thus far (CLOSED). The OPEN \r\nlist is implemented as a priority queue ordered in lowest f(n) order. What \r\nmakes A* interesting is that it continually re-evaluates the cost function for \r\nnodes as it re-encounters them. This allows A* to efficiently find the minimal \r\npath from the initial state to the goal state.\r\nLet’s now look at A* at a high level and then we’ll dig further and apply \r\nit to a well-known problem. Listing 3.4 provides the high level flow for A*.\r\nLISTING 3.4:  High-level flow for the A* search algorithm.\r\nInitialize OPEN list (priority queue)\r\nInitialize CLOSED list\r\nPlace start node on the OPEN list\r\nLoop while the OPEN list is not empty\r\n Get best node (parent) from OPEN list (least f (n))\r\n if parent is the goal node, done\r\n Place parent on the CLOSED list\r\n Expand parent to all adjacent nodes (adj_node)\r\n  if adj_node is on the CLOSED list\r\n   discard adj_node and continue\r\n  else if adj_node is on the OPEN list\r\n   if adj_node’s g value is better than \r\n    the OPEN.adj_node’s g value\r\n    discard OPEN.cur_node\r\n    calculate adj_node’s g, h and f values\r\n    set adj_node predecessor to parent\r\n    add adj_node to OPEN list\r\n    continue\r\n   end\r\n  else\r\n   calculate adj_node’s g, h and f values\r\n   set adj_node predecessor to parent\r\n","uuid":"78ea54d7-baa0-490e-88af-9cced0f664f7"},"_type":"pdf"},{"_id":"RZFSu4IBzLTTH-8HZymv","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":77,"pages":518,"text":"58 Artificial Intelligence\r\n   add adj_node to OPEN list\r\n  end\r\n end\r\nend loop\r\nNote in the flow from Listing 3.4 that once we find the best node from the \r\nOPEN list, we expand all of the child nodes (legal states possible from the \r\nbest node). If the new legal states are not found on either the OPEN or \r\nCLOSED lists, they are added as new nodes (setting the predecessor to the \r\nbest node, or parent). If the new node is on the CLOSED list, we discard \r\nit and continue. Finally, if the new node is on the OPEN list, but the new \r\nnode has a better g value, we discard the node on the OPEN list and add \r\nthe new node to the OPEN list (otherwise, the new node is discarded, if its g \r\nvalue is worse). By re-evaluating the nodes on the OPEN list, and replacing \r\nthem when cost functions permit, we allow better paths to emerge from the \r\nstate space.\r\nAs we’ve defined already, A* is complete, as long as the memory supports \r\nthe depth and branching factor of the tree. A* is also optimal, but this \r\ncharacteristic depends on the use of an admissible heuristic. Because A* \r\nmust keep track of the nodes evaluated so far (and also the discovered nodes \r\nto be evaluated), the time and space complexity are both O(bd).\r\nNOTE  The heuristic is defined as admissible if it accurately estimates the \r\npath cost to the goal, or underestimates it (remains optimistic). This \r\nrequires that the heuristic be monotonic, which means that the cost \r\nnever decreases over the path, and instead monotonically increases. This \r\nmeans that g(n) (path cost from the initial node to the current node) \r\nmonotonically increases, while h(n) (path cost from the current node to \r\nthe goal node) monotonically decreases.\r\nFIGURE 3.4: The Eight Puzzle and a demonstration of moving from an initial configuration to \r\nthe goal configuration (does not include all steps).\r\n","uuid":"4df09f01-8453-4ecf-8a7b-ea6f26230acc"},"_type":"pdf"},{"_id":"RpFSu4IBzLTTH-8HZymy","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":78,"pages":518,"text":"Informed Search 59\r\nA* Search and the Eight Puzzle\r\nWhile A* has been applied successfully to problem domains such as path-\r\nfinding, we’ll apply it here to what’s called the Eight Puzzle (also known \r\nas the N by M, or n2-1 tile puzzle). This particular variation of the puzzle \r\nconsists of eight tiles in a 3 by 3 grid. One location contains no tile, which \r\ncan be used to move other tiles to migrate from one configuration to another \r\n(see Figure 3.4).\r\nNote in Figure 3.4 that there are two legal moves that are possible. \r\nThe ‘1’ tile can move left, and the ‘6’ tile can move down. The final goal \r\nconfiguration is shown at the right. Note that this is one variation of the goal, \r\nand the one that we’ll use here.\r\nThe Eight Puzzle is interesting because it’s a difficult problem to solve, \r\nbut one that’s been studied at length and is therefore very well understood. \r\n[Archer 1999] For example, the number of possible board configurations of \r\nthe Eight Puzzle is (n*n)!, but only half of these are legal configurations.\r\nTIP  During the 1870s, the Fifteen Puzzle (4 by 4 variant of the N by M \r\npuzzle) became a puzzle craze much like the Rubik’s cube of the 1970s \r\nand 1980s.\r\nOn average, 22 moves are required to solve the 3 by 3 variant of the puzzle. \r\nBut considering 22 as the average depth of the tree, with an average branching \r\nfactor of 2.67, 2.4 trillion non-unique tile configurations can be evaluated.\r\nEight-Puzzle Representation\r\nWe’ll use a common representation for the Eight Puzzle, a linear vector \r\ncontaining the tile placement from left to right, top to bottom (see Figure \r\n3.5). This particular figure shows the moves possible from the initial puzzle \r\nconfiguration to depth two of this particular state space tree.\r\nFIGURE 3.5: Eight Puzzle configuration using a simple vector.\r\n","uuid":"fd6be713-320e-4943-a3b6-e84a787b8478"},"_type":"pdf"},{"_id":"R5FSu4IBzLTTH-8HZym1","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":79,"pages":518,"text":"60 Artificial Intelligence\r\nFor our heuristic, we’ll use the depth of the tree as the cost from the root to \r\nthe current node (otherwise known as g(n)), and the number of misplaced \r\ntiles (h(n)) as the estimated cost to the goal node (excluding the blank). The \r\npath cost (f(n)) then becomes the cost of the path to the current node (g(n)) \r\nplus the estimated cost to the goal node (h(n)). You can see these heuristics \r\nin the tree in Figure 3.6. From the root node, only two moves are possible, \r\nbut from these two moves, three new moves (states) open up. At the bottom \r\nof this tree, you can see that the cost function has decreased, indicating that \r\nthese board configurations are likely candidates to explore next.\r\nNOTE  There are two popular heuristics for the N-puzzle problem. The first is \r\nsimply the number of tiles out of place, which in general decreases as \r\nthe goal is approached. The other heuristic is the Manhattan distance of \r\nFIGURE 3.6: Eight Puzzle tree ending at depth two, illustrating the cost functions.\r\n","uuid":"cc493afc-bbf9-4d8d-9cc1-8b4d61b30741"},"_type":"pdf"},{"_id":"SJFSu4IBzLTTH-8HZym3","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":80,"pages":518,"text":"Informed Search 61\r\ntiles which sums the tile distance of each out of place tile to its correct \r\nlocation. For this implementation, we’ll demonstrate the simple, but \r\neffective, tiles-out-of-place heuristic.\r\nTIP  While there are (3*3)! board configurations possible, there are only \r\n(3*3)!/2 valid configurations. The other half of the configurations are \r\nunsolvable. We’ll not dwell on this here, but in the source implementation \r\nyou’ll see the test in initPuzzle using the concept of inversions to validate \r\nthe configuration of the board. This concept can be further explored in \r\n[KGong 2005].\r\nA* Search Implementation\r\nThe core the of A-star algorithm is implemented in the function astar(). This \r\nfunction implements A-star as shown in Listing 3.4. We’ll also present the \r\nevaluation function, which implements the ‘tiles-out-of-place’ metric. The \r\nlist and other support functions are not presented here, but are available on \r\nthe CD-ROM for review.\r\nNOTE  The A* implementation can be found on the CD-ROM at ./software/ch3/\r\nastar.c.\r\nLet’s start with the evaluation function which calculates the estimated cost \r\nfrom the current node to the goal (as the number of tiles out of place), see \r\nListing 3.6. The function simply enumerates the 3 by 3 board as a one-\r\ndimensional vector, incrementing a score value whenever a tile is present in \r\na position it should not be in. This score is then returned to the caller.\r\nLISTING 3.6: The Eight Puzzle h(n) estimated cost metric.\r\ndouble evaluateBoard( board_t *board_p )\r\n{\r\n  int i;\r\n  const int test[MAX_BOARD-1]={1, 2, 3, 4, 5, 6, 7, 8 };\r\n  int  score=0;\r\n  for (i = 0 ; i < MAX_BOARD-1 ; i++) {\r\n    score += (board_p->array[i] != test[i]);\r\n  }\r\n  return (double)score;\r\n}\r\n","uuid":"e58b0f95-77e4-42eb-bb96-e3bffa17ea5b"},"_type":"pdf"},{"_id":"SZFSu4IBzLTTH-8HZym6","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":81,"pages":518,"text":"62 Artificial Intelligence\r\nThe astar function is shown in Listing 3.7. Prior to calling this function, we’ve \r\nselected a random board configuration and placed it onto the OPEN list. We \r\nthen work through the OPEN list, retrieving the best node (with the least f \r\nvalue using getListBest) and immediately place it on the CLOSED list. We \r\ncheck to see if this node is the solution, and if so, we emit the path from \r\nthe initial node to the goal (which illustrates the moves that were made). To \r\nminimize searching too deeply in the tree, we halt enumerating nodes past \r\na given depth (we search them no further).\r\nThe next step is to enumerate the possible moves from this state, which \r\nwill be a maximum of four. The getChildBoard function is used to return \r\nan adjacent node (using the index passed in to determine which possible \r\nmove to make). If a move isn’t possible, then a NULL is returned and it’s \r\nignored.\r\nWith a new child node, we first check to see if it’s already been evaluated \r\n(if it’s on the CLOSED list). If it is, then we’re to destroy this node and \r\ncontinue (to get the child node for the current board configuration). If \r\nwe’ve not seen this particular board configuration before, we calculate the \r\nheuristics for the node. First, we initialize the node’s depth in the tree as the \r\nparent’s depth plus one. Next, we call evaluateBoard to get the tiles-out-of-\r\nplace metric, which will act as our h value (cost from the root node to this \r\nnode). The g value is set to the current depth, and the f value is initialized \r\nwith Eq 3.1.\r\n    (Eq 3.1)\r\nWe include an alpha and beta parameter here to give different weights to \r\nthe g and h values. In this implementation, alpha is 1.0 and beta is 2.0. This \r\nmeans that more weight is given to the h value, and subsequently the closer a \r\nnode is to the goal is weighed higher than its depth in the state space tree.\r\nWith the f value calculated, we check to see if the node is on the OPEN \r\nlist. If it is, we compare their f values. If the node on the OPEN list has a \r\nworse f value, the node on the OPEN list is discarded and the new child \r\nnode takes its place (setting the predecessor link to the parent, so we know \r\nhow we got to this node). If the node on the OPEN list has a better f value, \r\nthen the node on the OPEN list remains on the open list and the new child \r\nis discarded.\r\nFinally, if the new child node exists on neither the CLOSED or OPEN \r\nlist, it’s a new node that we’ve yet to see. It’s simply added to the OPEN list, \r\nand the process continues.\r\nThis algorithm continues until either one of two events occur. If the \r\nOPEN list becomes empty, then no solution was found and the algorithm \r\n","uuid":"723ad498-06e8-4536-81b8-aa8797f784e2"},"_type":"pdf"},{"_id":"SpFSu4IBzLTTH-8HZym8","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":82,"pages":518,"text":"Informed Search 63\r\nexits. If the solution is found, then showSolution is called, and the nodes \r\nlinked together via the predecessor links are enumerated to show the solution \r\nfrom the initial node to the goal node.\r\nLISTING 3.7: The A* algorithm.\r\nvoid astar( void )\r\n{\r\n  board_t *cur_board_p, *child_p, *temp;\r\n  int i;\r\n  /* While items are on the open list */\r\n  while ( listCount(&openList_p) ) {\r\n    /* Get the current best board on the open list */\r\n    cur_board_p = getListBest( &openList_p );\r\n    putList( &closedList_p, cur_board_p );\r\n    /* Do we have a solution? */\r\n    if (cur_board_p->h == (double)0.0) {\r\n      showSolution( cur_board_p );\r\n      return;\r\n    } else {\r\n      /* Heuristic - average number of steps is 22 for a 3x3, so \r\n       * don’t go too deep.\r\n       */\r\n      if (cur_board_p->depth > MAX_DEPTH) continue;\r\n      /* Enumerate adjacent states */\r\n      for (i = 0 ; i < 4 ; i++) {\r\n        child_p = getChildBoard( cur_board_p, i );\r\n        if (child_p != (board_t *)0) {\r\n          if ( onList(&closedList_p, child_p->array, NULL) ) {\r\n            nodeFree( child_p );\r\n            continue;\r\n          }\r\n          child_p->depth = cur_board_p->depth + 1;\r\n          child_p->h = evaluateBoard( child_p );\r\n          child_p->g = (double)child_p->depth;\r\n          child_p->f = (child_p->g * ALPHA) + (child_p->h * BETA);\r\n          /* New child board on the open list? */\r\n          if ( onList(&openList_p, child_p->array, NULL) ) {\r\n            temp = getList(&openList_p, child_p->array);\r\n            if (temp->g < child_p->g) {\r\n","uuid":"b52fa93d-acc7-437d-b747-08a6b1917297"},"_type":"pdf"},{"_id":"S5FSu4IBzLTTH-8HZym_","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":83,"pages":518,"text":"64 Artificial Intelligence\r\n              nodeFree(child_p);\r\n              putList(&openList_p, temp);\r\n              continue;\r\n            }\r\n            nodeFree( temp );\r\n          } else {\r\n            /* Child board either doesn’t exist, or is better than a \r\n             * previous board.  Hook it to the parent and place on the\r\n             * open list.\r\n             */\r\n            child_p->pred = cur_board_p;\r\n            putList( &openList_p, child_p );\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  return;\r\n}\r\nEight Puzzle Demonstration with A*\r\nIn the implementation, the tiles are labeled A-H with a space used to denote \r\nthe blank tile. Upon execution, once the solution is found, the path taken \r\nfrom the initial board to the goal is enumerated. This is shown below in \r\nListing 3.8, minimized for space.\r\nLISTING 3.8: A sample run of the A* program to solve the Eight Puzzle.\r\n$./astar\r\nGBD\r\nFCH\r\n EA\r\nBGD\r\nFCH\r\nE A\r\nBGD\r\nFCH\r\nEA\r\nGBD\r\nFC\r\n","uuid":"7bb93c08-51c7-44dc-aa5a-3c94e47a8075"},"_type":"pdf"},{"_id":"TJFSu4IBzLTTH-8HZynB","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":84,"pages":518,"text":"Informed Search 65\r\nEAH\r\n...\r\nABC\r\n DF\r\nGEH\r\nABC\r\nD F\r\nGEH\r\nABC\r\nDEF\r\nG H\r\nABC\r\nDEF\r\nGH\r\nA* Variants\r\nThe popularity of A* has spawned a number of variants that offer different \r\ncharacteristics. The Iterative-Deepening A* algorithm backtracks to other \r\nnodes when the cost of the current branch exceeds a threshold. To minimize \r\nthe memory requirements of A*, the Simplified Memory-Bounded A* \r\nalgorithm (SMA*) was created. SMA* uses the memory made available to \r\nit, and when it runs out of memory, the algorithm drops the least promising \r\nnode to make room for new search nodes from the frontier.\r\nApplications of A* Search\r\nA* search is a popular technique and has seen use as a path-finding algorithm \r\nfor computer strategy games. For better performance, many games employ \r\nsimpler shortcut methods for path-finding by limiting the space of their \r\nmovement (using a much sparser graph over the landscape), or by pre-\r\ncalculating routes for in-game use.\r\nHILL-CLIMBING SEARCH\r\nHill climbing is an iterative improvement algorithm that is similar to greedy \r\nbest-first search, except that backtracking is not permitted. At each step in \r\nthe search, a single node is chosen to follow. The criterion for the node to \r\nfollow is that it’s the best state for the current state. Since the frontier for the \r\nsearch is a single node, the algorithm is also similar to beam search using a \r\nbeam width of one (our OPEN list can contain exactly one node).\r\n","uuid":"79527e58-e911-492c-9ff2-649004070245"},"_type":"pdf"},{"_id":"TZFSu4IBzLTTH-8HZynE","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":85,"pages":518,"text":"66 Artificial Intelligence\r\nThe problem with hill climbing is that the best node to enumerate locally \r\nmay not be the best node globally. For this reason, hill climbing can lead to \r\nlocal optimums, but not necessarily the global optimum (the best solution \r\navailable). Consider the function in Figure 3.7. There exists a local optimum \r\nand a global optimum. The goal should be to maximize the function, but if \r\nwe begin at the far left and work our way toward the global optimum, we \r\nget stuck at the local optimum.\r\nSIMULATED ANNEALING (SA)\r\nSimulated Annealing (SA) is another iterative improvement algorithm in \r\nwhich randomness is incorporated to expand the search space and avoid \r\nbecoming trapped in local minimum. As the name implies, the algorithm \r\nsimulates the process of annealing. \r\nAnnealing is a technique in metal-casting where molten metal is heated \r\nand then cooled in a gradual manner to evenly distribute the molecules into a \r\ncrystalline structure. If the metal is cooled too quickly, a crystalline structure \r\ndoes not result, and the metal solid is weak and brittle (having been filled with \r\nbubbles and cracks). If cooled in a gradual and controlled way, a crystalline \r\nstructure forms at a molecular level resulting in great structural integrity.\r\nThe basic algorithm for simulated annealing is shown in Listing 3.9. We \r\nstart with an initial solution candidate and the loop while the temperature is \r\ngreater than zero. In this loop, we create an adjacent candidate solution by \r\nperturbing our current solution. This changes the solution to a neighboring \r\nsolution, but at random. We then calculate the delta energy between the \r\nnew (adjacent) solution, and our current solution. If this delta energy is less \r\nFIGURE 3.7: State space illustrating the problem with hill climbing.\r\n","uuid":"e55b5b86-1e71-4db5-b655-d4a1ebc23b24"},"_type":"pdf"},{"_id":"TpFSu4IBzLTTH-8HZynG","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":86,"pages":518,"text":"Informed Search 67\r\nthan zero, then our new solution is better than the old, and we accept it (we \r\nmove the new adjacent solution to our current solution).\r\nLISTING 3.9: Simulated annealing algorithm.\r\nsimulated_annealing()\r\n{\r\n  cur_solution = random()\r\n  computeE( cur_solution )\r\n  while (Temperature > 0)\r\n  adj_solution = perturb_solution( cur_solution )\r\n  computeE( adj_solution )\r\n  deltaE = adj_solution.energy – cur_solution.energy\r\n  /* Is new solution better, then take it */\r\n  if (deltaE < 0)\r\n    cur_solution = adj_solution\r\n  else\r\n    p = exp( -deltaE / Temperature )\r\n    /* Randomly accept worse solution */\r\n    if ( p > RANDOM(0..1) )\r\n      cur_solution = adj_solution\r\n    end\r\n  end\r\n    reduce Temperature\r\n  end\r\nend simulated_annealing\r\nIf our new solution was not better than the old, then we accept it with a \r\nprobability proportional to the current temperature and the delta energy. \r\nThe lower the temperature, the less likely we’ll accept a worse solution. But \r\nthe better the delta energy, the more likely we’ll accept it. This probability \r\nis calculated as shown in Eq 3.2.\r\n    (Eq 3.2)\r\nSince our temperature decreases over time, it’s less likely that a worse \r\nsolution will be accepted. Early on when the temperature is high, worse \r\nsolutions can be accepted allowing the search to move away from local \r\nmaximum in search of the global maximum. As the temperature decreases, \r\nit becomes more difficult to accept a worse solution, which means that the \r\nalgorithm settles on a solution and simply fine-tunes it (if possible).\r\n","uuid":"38e6c190-479d-4d7e-8235-33b2deac8c11"},"_type":"pdf"},{"_id":"T5FSu4IBzLTTH-8HZynJ","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":87,"pages":518,"text":"68 Artificial Intelligence\r\nThe classical simulated annealing algorithm also includes monte carlo \r\ncycles where a number of trials are performed before decreasing the \r\ntemperature.\r\nThe Traveling Salesman Problem (TSP)\r\nTo demonstrate the simulated annealing algorithm, we’ll use the classic \r\nTraveling Salesman Problem (or TSP). In the TSP, we’re given a set of cities \r\nand a relative cost for traveling between each city to each other. The goal \r\nis to find a path through all cities where we visit all cities once, and find the \r\nshortest overall tour. We’ll start at one city, visit each other city, and then \r\nend at the initial city.\r\nConsider the graph shown in Figure 3.8. Many cities are connected to \r\none another, but an optimal path exists that tours each city only once.\r\nThe TSP is both interesting and important because it has practical \r\nimplications. Consider transportation problems where deliveries are required \r\nand fuel and time are to be minimized. Another interesting application is \r\nthat of drilling holes in a circuit board. A number of holes must be drilled \r\nquickly on a single board, and in order to do this, an optimal path is needed \r\nto minimize the movement of the drill (which will be slow). Solutions to the \r\nTSP can therefore be very useful.\r\nTSP Tour Representation\r\nTo represent a set of cities and the tour between them, we’ll use an implicit \r\nadjacency list. Each city will be contained in the list, and cities that are next \r\nto one another are implied as connected in the tour. Recall our sample TSP \r\nin Figure 3.8 where seven cities make up the world. This will be represented \r\nas shown in Figure 3.9.\r\nFIGURE 3.8: A Sample TSP tour through a small graph.\r\n","uuid":"d1e35b08-d98f-402b-91a0-21c7ebd2251d"},"_type":"pdf"},{"_id":"UJFSu4IBzLTTH-8HZynM","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":88,"pages":518,"text":"Informed Search 69\r\nFIGURE 3.9: Adjacency list for the TSP tour shown in Figure 3.8.\r\nFIGURE 3.10: Demonstration of row swapping to perturb the tour.\r\n","uuid":"f2730c05-fd66-41ca-94b5-ea77052672b3"},"_type":"pdf"},{"_id":"UZFSu4IBzLTTH-8HZynO","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":89,"pages":518,"text":"70 Artificial Intelligence\r\nNote that the list shown in Figure 3.9 is a single list in tour order. When \r\nwe reach the end of the list, we wrap to the first element, completing the \r\ntour. To perturb the tour we take two random rows from the list and swap \r\nthem. This is demonstrated in Figure 3.10. Note how by simply swapping \r\ntwo elements, the tour is greatly perturbed and results in a worse tour \r\nlength.\r\nSimulated Annealing Implementation\r\nThe implementation of simulated annealing is actually quite simple in the \r\nC language. We’ll review three of the functions that make up the simulated \r\nannealing implementation, the main simulated annealing algorithm, \r\nperturbing a tour, and computing the length of the tour. The remaining \r\nfunctions are available on the CD-ROM.\r\nLISTING 3.10: Structures for the TSP solution.\r\ntypedef struct {\r\n int x, y;\r\n} city_t;\r\ntypedef struct {\r\ncity_t cities[MAX_CITIES];\r\ndouble tour_length;\r\n} solution_t;\r\nThe Euclidean distance of the tour is calculated with compute_tour. This \r\nfunction walks through the tour, accumulating the segments between each \r\ncity (see Listing 3.11). It ends by wrapping around the list, and adding in the \r\ndistance from the last city back to the first.\r\nLISTING 3.11: Calculating the Euclidean tour with compute_tour.\r\nvoid compute_tour( solution_t *sol )\r\n{\r\n  int i;\r\n  double tour_length = (double)0.0;\r\n  for (i = 0 ; i < MAX_CITIES-1 ; i++) {\r\n    tour_length +=\r\n         euclidean_distance( \r\n                      sol->cities[i].x, sol->cities[i].y,\r\n                      sol->cities[i+1].x, sol->cities[i+1].y );\r\n","uuid":"2c9c204a-9048-4a64-be8f-2389e9ea2ef9"},"_type":"pdf"},{"_id":"UpFSu4IBzLTTH-8HZynR","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":90,"pages":518,"text":"Informed Search 71\r\n    \r\n  }\r\ntour_length +=\r\n     euclidean_distance( \r\n                      sol->cities[MAX_CITIES-1].x, \r\n                      sol->cities[MAX_CITIES-1].y,\r\n                      sol->cities[0].x, sol->cities[0].y );\r\n  sol->tour_length = tour_length;\r\n  return;\r\n}\r\nGiven a solution, we can create an adjacent solution using the function \r\nperturb_tour. In this function, we randomly select two cities in the tour, and \r\nswap them. A loop exists to ensure that we’ve selected two unique random \r\npoints (so that we don’t swap a single city with itself). Once selected, the x \r\nand y coordinates are swapped and the function is complete.\r\nLISTING 3.12: Perturbing the tour by creating an adjacent solution.\r\nvoid perturb_tour( solution_t *sol )\r\n{\r\n  int p1, p2, x, y;\r\n  do {\r\n    p1 = RANDMAX(MAX_CITIES);\r\n    p2 = RANDMAX(MAX_CITIES);\r\n  } while (p1 == p2);\r\n  x = sol->cities[p1].x;\r\n  y = sol->cities[p1].y;\r\n  sol->cities[p1].x = sol->cities[p2].x;\r\n  sol->cities[p1].y = sol->cities[p2].y;\r\n  sol->cities[p2].x = x;\r\n  sol->cities[p2].y = y;\r\n  return;\r\n}\r\nFinally, the simulated_annealing function implements the core of \r\nthe simulated annealing algorithm. The algorithm loops around the \r\ntemperature, constantly reducing until it reaches a value near zero. \r\nThe initial solution has been initialized prior to this function. We take \r\nthe current solution and perturb it (randomly alter it) for a number of \r\n","uuid":"b73445b3-4393-4e02-a316-1aa302f6716a"},"_type":"pdf"},{"_id":"U5FSu4IBzLTTH-8HZynT","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":91,"pages":518,"text":"72 Artificial Intelligence\r\niterations (the Monte Carlo step). If the new solution is better, we accept \r\nit by copying it into the current solution. If the new solution is worse, \r\nthen we accept it with a probability defined by Eq 3.2. The worse the new \r\nsolution and the lower the temperature, the less likely we are to accept the \r\nnew solution. When the Monte Carlo step is complete, the temperature \r\nis reduced and the process continues. When the algorithm completes, we \r\nemit the city tour.\r\nLISTING 3.13: The simulated annealing main function implementation.\r\nint simulated_annealing( void )\r\n{\r\n  double temperature = INITIAL_TEMP, delta_e;\r\n  solution_t tempSolution;\r\n  int iteration;\r\n  while( temperature > 0.0001 ) {\r\n    /* Copy the current solution to a temp */\r\n    memcpy( (char *)&tempSolution, \r\n             (char *)&curSolution, sizeof(solution_t) );\r\n    /* Monte Carlo Iterations */\r\n    for (iteration = 0 ; \r\n          iteration < NUM_ITERATIONS ; iteration++) {\r\n      perturb_tour( &tempSolution );\r\n      compute_tour( &tempSolution );\r\n      delta_e = tempSolution.tour_length – \r\n                 curSolution.tour_length;\r\n      /* Is the new solution better than the old? */\r\n      if (delta_e < 0.0) {\r\n        /* Accept the new, better, solution */\r\n        memcpy( (char *)&curSolution,\r\n                 (char *)&tempSolution, sizeof(solution_t) );\r\n      } else {\r\n        /* Probabilistically accept a worse solution */\r\n        if ( exp( (-delta_e / temperature) ) > RANDOM()) {\r\n          memcpy( (char *)&curSolution,\r\n                   (char *)&tempSolution, sizeof(solution_t) );\r\n        }\r\n      }\r\n    }\r\n    /* Decrease the temperature */\r\n","uuid":"7523b55f-73de-4524-8dec-e25e46d4ff24"},"_type":"pdf"},{"_id":"VJFSu4IBzLTTH-8HZynW","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":92,"pages":518,"text":"Informed Search 73\r\n    temperature *= ALPHA;\r\n  }\r\n  return 0;\r\n}\r\nSimulated annealing permits a random walk through a state space, greedily \r\nfollowing the best path. But simulated annealing also probabilistically allows \r\nfollowing worse paths in an effort to escape local maximums in search of \r\nthe global maximum. This makes simulated annealing a random search, \r\nbut heuristically driven. For all of its advantages, simulated annealing is \r\nincomplete and suboptimal.\r\nSimulated Annealing Demonstration\r\nLet’s now look at the simulated annealing algorithm in action. We’ll look at \r\nthe algorithm from a variety of perspectives, from the temperature schedule, \r\nto a sample solution to TSP for 25 cities.\r\nFIGURE 3.11: The temperature decay curve using Eq 3.3.\r\n","uuid":"002d4ee1-7a91-4527-99c4-43797706be45"},"_type":"pdf"},{"_id":"VZFSu4IBzLTTH-8HZynY","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":93,"pages":518,"text":"74 Artificial Intelligence\r\nThe temperature schedule is a factor in the probability for accepting a \r\nworse solution. In this implementation, we’ll use a geometric decay for the \r\ntemperature, as shown in Eq 3.3.\r\n T = aT    (Eq 3.3)\r\nIn this case, we use an alpha of 0.999. The temperature decay using this \r\nequation is shown in Figure 3.11.\r\nThe relative fitness of the solution over a run is shown in Figure 3.12. \r\nThis graph shows the length of the tour during the decrease in temperature. \r\nNote at the left-hand side of the graph that the relative fitness is very erratic. \r\nThis is due to the high temperature accepting a number of poorer solutions. \r\nAs the temperature decreases (moving to the right of the graph), poorer \r\nsolutions are not accepted as readily. At the left-hand side of the graph, the \r\nalgorithm permits exploration of the state space, where at the right-hand of \r\nthe graph, the solution is fine-tuned.\r\nA sample TSP tour is shown finally in Figure 3.13. This particular \r\nsolution was for a 25 city tour.\r\nFIGURE 3.12: The relative fitness.\r\n","uuid":"20eab46c-cdb1-4f20-821e-f494b20f8f59"},"_type":"pdf"},{"_id":"VpFSu4IBzLTTH-8HZynb","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":94,"pages":518,"text":"Informed Search 75\r\nTABU SEARCH\r\nTabu search is a very simple search algorithm that is easy to implement and \r\ncan be very effective. The basic idea behind Tabu search is neighborhood \r\nsearch with a Tabu list of nodes that is made up of nodes previously evaluated. \r\nTherefore, the search may deteriorate, but this allows the algorithm to widen \r\nthe search to avoid becoming stuck in local maxima. During each iteration \r\nof the algorithm, the current search candidate is compared against the best \r\nsolution found so far so that the best node is saved for later. After some \r\nsearch criteria has been met (a solution found, or a maximum number of \r\niterations) the algorithm exits.\r\nThe Tabu list can be of finite size so that the oldest nodes can be dropped \r\nmaking room for new Tabu nodes. The nodes on the Tabu list can also be \r\ntimed, such that a node can only be Tabu for some period of time. Either \r\ncase allows the algorithm to reuse the Tabu list and minimize the amount \r\nof memory needed.\r\nFIGURE 3.13: Sample TSP tour optimized by simulated annealing.\r\n","uuid":"22fa839a-46a1-42c4-a552-d24decb92da4"},"_type":"pdf"},{"_id":"V5FSu4IBzLTTH-8HZyne","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":95,"pages":518,"text":"76 Artificial Intelligence\r\nMonitoring Tabu search through the state space of the 4-Queens problem \r\nis shown in Figure 3.14. The initial position is the root, which has a score \r\nof three (three conflicts). The goal is to minimize the score, where zero is a \r\nsolution (goal node). At the first iteration, the neighbor nodes are evaluated, \r\nand the best selected. Note also here that our initial node has been placed \r\non the Tabu list. At iteration two, the neighbors are evaluated for the current \r\nnode and the best is chosen to move forward. The Tabu list now contains the \r\nprevious two best nodes. In this iteration, we’ve found a node with a score of \r\nzero, which indicates a goal node and the algorithm terminates.\r\nThe basic flow for Tabu search is shown in Listing 3.14. Given an initial \r\nposition (shown here as a initial random position), the search space is \r\nenumerated by taking the best neighbor node that is not Tabu. If it’s better \r\nthan our best saved solution, it becomes the best solution. The process then \r\ncontinues with the last solution until a termination criteria is met.\r\nFIGURE 3.14: The 4-Queens problem solved by Tabu search.\r\n","uuid":"538436b9-fc99-4c3c-ada1-a36d1bc2e0e5"},"_type":"pdf"},{"_id":"WJFSu4IBzLTTH-8HZyng","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":96,"pages":518,"text":"Informed Search 77\r\nLISTING 3.14: The basic flow of the Tabu search algorithm.\r\ntabu_search()\r\n{\r\ncur_solution = random()\r\nevaluate_position( cur_solution )\r\nbest = cur_solution\r\n  tabu( cur_solution )\r\n  while (!termination_critera) {\r\n    /* Get the best neighbor, not on the tabu list */\r\n    cur_solution = best_non_tabu_neighbor( cur_solution )\r\n    evaluate_position( cur_solution )\r\n    tabu( cur_solution )\r\n    if (cur_solution.f < best.f) {\r\n      best = cur_solution\r\n    \r\n    }\r\n}\r\n  return best\r\n}\r\nTo illustrate the Tabu search algorithm, we’ll use the N-Queens problem \r\nas demonstrated with the best-first search algorithm. (See Figure 3.1 for a \r\nrecap of the problem and desired solution.) After discussing the basic Tabu \r\nsearch implementation, we’ll explore some of the variants that improve the \r\nalgorithm.\r\nTabu Search Implementation\r\nThe Tabu search algorithm is very simple and can be illustrated in a single \r\nfunction (see Listing 3.15, function tabu_s). This function is the core of \r\nthe Tabu search algorithm. The supporting functions are not shown here, \r\nbut are available on the CD-ROM.\r\nO\r\nN THE CD\r\n The C source language implementation of Tabu search can be found on \r\nthe CD-ROM at ./software/ch3/tabus.c.\r\nThe implementation begins with a seeding of the random function \r\n(RANDINIT) followed by the creation of the Tabu queue. This queue \r\nrepresents our Tabu list, or those elements that will not be evaluated further \r\n","uuid":"42439c70-bc6c-451b-9033-dbc5e0d81c21"},"_type":"pdf"},{"_id":"WZFSu4IBzLTTH-8HZynj","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":97,"pages":518,"text":"78 Artificial Intelligence\r\nif rediscovered. The initial solution is then created, and copied to the best \r\nsolution (via initBoard to create the solution, and evaluateBoard to evaluate \r\nthe value of the solution). The current solution is then loaded onto the Tabu \r\nlist so that it’s not evaluated again.\r\nThe loop then begins, for which we’ll operate forever, or until a solution \r\nis found. For this simple problem, we’ll always find a solution in some \r\nnumber of iterations. The call to reviewChildNodes evaluates the neighbor \r\nsolutions, and picks the best one that is not on the Tabu list. This solution is \r\nreturned (by reference) and then loaded onto the Tabu list. Note here that \r\nwe first check to see if it’s already on the Tabu list. If not, we check the state \r\nof the Tabu list. If full, we need the oldest element to make room for the \r\nnew node, and then add it to the queue.\r\nTIP  Recall that queues are FIFO in nature. Therefore, removing a node from \r\nthe queue automatically removes the oldest node, satisfying the policy \r\nfor the algorithm (remove the oldest node first, if the Tabu list is full).\r\nFinally, we check the value of the solution, and if zero, we have the goal node. \r\nThis can now be emitted using the emitBoard function.  \r\nLISTING 3.15: Basic Tabu search algorithm implementation in C.\r\nvoid tabu_s()\r\n{\r\n  unsigned short best_sol, cur_sol;\r\n  int best_f, cur_f;\r\n  RANDINIT();\r\n  tabu_q = createQueue(MAX_ELEMENTS);\r\n  /* Get initial board */\r\n  cur_sol = best_sol = initBoard();\r\n  cur_f = best_f = evaluateBoard( best_sol ); \r\n  enQueue( tabu_q, best_sol );\r\n  while( 1 ) {\r\n    printf(“Iteration for %x\\n”, cur_sol);\r\n    /* Return (by reference) the best non-tabu neighbor */\r\n    reviewChildNodes( &cur_sol, &cur_f );\r\n    /* Add the current best solution to the tabu list (remove\r\n     * the oldest if needed).\r\n     */\r\n    if (!searchQueue( tabu_q, cur_sol )) {\r\n      if (isFullQueue( tabu_q )) {\r\n","uuid":"300ce570-3d4f-44c6-9ff8-47dcdb1dc348"},"_type":"pdf"},{"_id":"WpFSu4IBzLTTH-8HZynl","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":98,"pages":518,"text":"Informed Search 79\r\n        (void)deQueue( tabu_q );\r\n      }\r\n      enQueue( tabu_q, cur_sol );\r\n    }\r\n    /* Save the best solution so far */\r\n    if (cur_f <= best_f) {\r\n      best_sol = cur_sol;\r\n      best_f = cur_f;\r\n    }\r\n    /* Solution found? */\r\n    if (best_f == 0 ) {\r\n      emitBoard( best_sol );\r\n      break;\r\n    }\r\n  }\r\n  destroyQueue( tabu_q );\r\n  return;\r\n}\r\nTabu Search Demonstration\r\nThe Tabu search application efficiently finds the solution to this problem (a \r\nstate space of 256 unique nodes). The first evaluateBoard is the initial node \r\n(see Listing 3.16), followed by four iterations of the algorithm. Note that while \r\nthe initial node had a cost of two, subsequent nodes evaluated were worse, \r\nbut eventually led to the goal. Tabu search permits the evaluation away from \r\nlocal minimum to find the global minimum, as demonstrated here.\r\nLISTING 3.16: Sample execution of Tabu search for the 4-Queens problem.\r\nevaluateBoard 1281 = (f 2)\r\nIteration for 1281\r\n evaluateBoard 2281 = (f 2)\r\n evaluateBoard 2181 = (f 3)\r\n evaluateBoard 2481 = (f 3)\r\n evaluateBoard 2241 = (f 2)\r\n evaluateBoard 2221 = (f 3)\r\n evaluateBoard 2281 = (f 2)\r\n evaluateBoard 2282 = (f 3)\r\nIteration for 2281\r\n evaluateBoard 4281 = (f 1)\r\n","uuid":"57371aae-3757-4719-bf7f-a42fd9a009cd"},"_type":"pdf"},{"_id":"W5FSu4IBzLTTH-8HZyno","_index":"distant_rl_history","_score":5.852623,"_source":{"citeKey":"JTArtificial08","created":1193755389000,"fileName":"[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","filePath":"D:\\Dropbox\\NEra\\New_Core_Reading\\[R] [[JTArtificial08]] Jones, TimM - 2008 - Artificial intelligence - a systems approach.pdf","modified":1656274746000,"pageIndex":99,"pages":518,"text":"80 Artificial Intelligence\r\n evaluateBoard 4181 = (f 1)\r\n evaluateBoard 4481 = (f 3)\r\n evaluateBoard 4281 = (f 1)\r\n evaluateBoard 4241 = (f 3)\r\n evaluateBoard 4282 = (f 2)\r\nIteration for 4281\r\n evaluateBoard 8281 = (f 2)\r\n evaluateBoard 8181 = (f 3)\r\n evaluateBoard 8481 = (f 4)\r\n evaluateBoard 8241 = (f 2)\r\n evaluateBoard 8221 = (f 3)\r\n evaluateBoard 8281 = (f 2)\r\n evaluateBoard 8282 = (f 2)\r\nIteration for 8282\r\n evaluateBoard 4282 = (f 2)\r\n evaluateBoard 2282 = (f 3)\r\n evaluateBoard 4182 = (f 0)\r\n evaluateBoard 4482 = (f 2)\r\n evaluateBoard 4282 = (f 2)\r\n evaluateBoard 4142 = (f 2)\r\n evaluateBoard 4181 = (f 1)\r\n evaluateBoard 4184 = (f 3)\r\nsolution is 0x4182\r\n0 1 0 0 \r\n0 0 0 1 \r\n1 0 0 0 \r\n0 0 1 0\r\nTabu Search Variants\r\nIn order to make Tabu search more effective for very difficult search problems, \r\na number of modifications exist. The first of these is called intensification and \r\nessentially intensifies the search around a given point (such as the best known \r\nsolution). The idea is that we take a promising node, and intensify the search \r\naround this point. This is implemented using an intermediate memory, which \r\ncontains the neighbor nodes to dig into further.\r\nOne issue that comes up in local search algorithms is that they can get \r\nstuck in local optimums. Tabu search introduces the concept of diversification \r\nto allow the algorithm to search nodes that have been previously unexplored \r\nto expand the space of search.\r\n","uuid":"53878c38-df57-4d0c-92fa-ab138abf268c"},"_type":"pdf"}],"max_score":5.852623,"total":{"relation":"eq","value":518}},"timed_out":false,"took":4}